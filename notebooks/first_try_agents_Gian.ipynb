{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231efb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, ModelSettings, TResponseInputItem, Runner, RunConfig, trace\n",
    "from openai.types.shared.reasoning import Reasoning\n",
    "from pydantic import BaseModel\n",
    "import asyncio\n",
    "\n",
    "my_agent_italian = Agent(\n",
    "  name=\"My agent\",\n",
    "  instructions=\"translate the text from english to italian\",\n",
    "  model=\"gpt-5-nano\",\n",
    "  model_settings=ModelSettings(\n",
    "    store=True,\n",
    "    reasoning=Reasoning(\n",
    "      effort=\"medium\"\n",
    "    )\n",
    "  )\n",
    ")\n",
    "\n",
    "\n",
    "my_agent_norwegian = Agent(\n",
    "  name=\"My agent\",\n",
    "  instructions=\"translate the text from english to norwegian\",\n",
    "  model=\"gpt-5-nano\",\n",
    "  model_settings=ModelSettings(\n",
    "    store=True,\n",
    "    reasoning=Reasoning(\n",
    "      effort=\"medium\"\n",
    "    )\n",
    "  )\n",
    ")\n",
    "\n",
    "class WorkflowInput(BaseModel):\n",
    "  input_as_text: str\n",
    "\n",
    "\n",
    "# Main code entrypoint\n",
    "async def run_workflow(workflow_input: WorkflowInput):\n",
    "  with trace(\"New agent\"):\n",
    "    state = {\n",
    "\n",
    "    }\n",
    "    workflow = workflow_input.model_dump()\n",
    "    conversation_history: list[TResponseInputItem] = [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"input_text\",\n",
    "            \"text\": workflow[\"input_as_text\"]\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "    my_agent_result_temp = await Runner.run(\n",
    "      my_agent_italian,\n",
    "      input=[\n",
    "        *conversation_history\n",
    "      ],\n",
    "      run_config=RunConfig(trace_metadata={\n",
    "        \"__trace_source__\": \"agent-builder\",\n",
    "        \"workflow_id\": \"wf_6999f5a59ce081908c90a7be4ec498ee0610a5b2e27c4494\"\n",
    "      })\n",
    "    )\n",
    "\n",
    "    conversation_history.extend([item.to_input_item() for item in my_agent_result_temp.new_items])\n",
    "\n",
    "    my_agent_result = {\n",
    "      \"output_text\": my_agent_result_temp.final_output_as(str)\n",
    "    }\n",
    "\n",
    "    return my_agent_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d5c463",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'final_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28minput\u001b[39m = WorkflowInput(input_as_text=\u001b[33m\"\u001b[39m\u001b[33mHello, my name is Gian Marco and I am a developer.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m run_workflow(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinal_output\u001b[49m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'final_output'"
     ]
    }
   ],
   "source": [
    "input = WorkflowInput(input_as_text=\"Hello, my name is Gian Marco and I am a developer.\")\n",
    "\n",
    "result = await run_workflow(input)\n",
    "\n",
    "print(result[\"output_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d87ef529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, ModelSettings, TResponseInputItem, Runner, RunConfig, trace\n",
    "from openai.types.shared.reasoning import Reasoning\n",
    "from pydantic import BaseModel\n",
    "import asyncio\n",
    "\n",
    "# 1. Define the Orchestrator Agent\n",
    "orchestrator_agent = Agent(\n",
    "  name=\"Orchestrator\",\n",
    "  instructions=\"\"\"Determine which language the user wants to translate their text into. \n",
    "  Reply strictly with exactly one word: 'italian' or 'norwegian'. \n",
    "  If it's unclear, default to 'italian'.\"\"\",\n",
    "  model=\"gpt-5-nano\",\n",
    "  model_settings=ModelSettings(store=False) \n",
    ")\n",
    "\n",
    "my_agent_italian = Agent(\n",
    "  name=\"Italian Translator\",\n",
    "  instructions=\"translate the text from english to italian\",\n",
    "  model=\"gpt-5-nano\",\n",
    "  model_settings=ModelSettings(store=True, reasoning=Reasoning(effort=\"medium\"))\n",
    ")\n",
    "\n",
    "my_agent_norwegian = Agent(\n",
    "  name=\"Norwegian Translator\",\n",
    "  instructions=\"translate the text from english to norwegian\",\n",
    "  model=\"gpt-5-nano\",\n",
    "  model_settings=ModelSettings(store=True, reasoning=Reasoning(effort=\"medium\"))\n",
    ")\n",
    "\n",
    "class WorkflowInput(BaseModel):\n",
    "  input_as_text: str\n",
    "\n",
    "# Main code entrypoint\n",
    "async def run_workflow(workflow_input: WorkflowInput):\n",
    "  with trace(\"New agent\"):\n",
    "    workflow = workflow_input.model_dump()\n",
    "    conversation_history: list[TResponseInputItem] = [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"input_text\",\n",
    "            \"text\": workflow[\"input_as_text\"]\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "\n",
    "    # --- STEP 1: Run the Orchestrator ---\n",
    "    orchestrator_result = await Runner.run(\n",
    "      orchestrator_agent,\n",
    "      input=[*conversation_history]\n",
    "    )\n",
    "    \n",
    "    # Extract the routing decision and clean up the text\n",
    "    decision = orchestrator_result.final_output_as(str).strip().lower()\n",
    "\n",
    "    # --- STEP 2: Route to the correct agent ---\n",
    "    if \"norwegian\" in decision:\n",
    "        selected_agent = my_agent_norwegian\n",
    "    else:\n",
    "        selected_agent = my_agent_italian\n",
    "\n",
    "    # --- STEP 3: Run the selected agent ---\n",
    "    my_agent_result_temp = await Runner.run(\n",
    "      selected_agent,\n",
    "      input=[*conversation_history],\n",
    "      run_config=RunConfig(trace_metadata={\n",
    "        \"__trace_source__\": \"agent-builder\",\n",
    "        \"workflow_id\": \"wf_6999f5a59ce081908c90a7be4ec498ee0610a5b2e27c4494\"\n",
    "      })\n",
    "    )\n",
    "\n",
    "    conversation_history.extend([item.to_input_item() for item in my_agent_result_temp.new_items])\n",
    "\n",
    "    return {\n",
    "      \"routed_to\": selected_agent.name, \n",
    "      \"output_text\": my_agent_result_temp.final_output_as(str)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e2e434f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hei, jeg heter Gian Marco og jeg er en utvikler.\n"
     ]
    }
   ],
   "source": [
    "input = WorkflowInput(input_as_text=\"Please translate this sentence in norwegian: Hello, my name is Gian Marco and I am a developer.\")\n",
    "\n",
    "result = await run_workflow(input)\n",
    "\n",
    "print(result[\"output_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b647c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, ModelSettings, TResponseInputItem, Runner, RunConfig, trace, function_tool\n",
    "\n",
    "class WorkflowInput(BaseModel):\n",
    "    file_path: str\n",
    "    instruction: str\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "@function_tool\n",
    "def calculate_excel_mean(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Reads a single-column Excel file and calculates the mathematical mean of its values.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): The absolute or relative path to the .xlsx file.\n",
    "        \n",
    "    Returns:\n",
    "        str: A sentence containing the calculated mean, or an error message if it fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        df = pd.read_excel(file_path)\n",
    "        first_column = df.columns[0]\n",
    "        mean_value = df[first_column].mean()\n",
    "        \n",
    "        return f\"The mean of the column '{first_column}' is {mean_value}.\"\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: Could not find an Excel file at the path '{file_path}'.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error processing the Excel file: {str(e)}\"\n",
    "\n",
    "excel_agent = Agent(\n",
    "    name=\"Excel Handler\",\n",
    "    instructions=\"You handle Excel files. Use your tool to read the file and execute the user's mathematical instruction. Don't suggest more things to do, strictly reply with what the user asks for.\",\n",
    "    model=\"gpt-5-nano\",\n",
    "    model_settings=ModelSettings(store=True, reasoning=Reasoning(effort=\"high\")),\n",
    "    tools=[calculate_excel_mean] # Give the agent the ability to read the file\n",
    ")\n",
    "\n",
    "text_agent = Agent(\n",
    "    name=\"Text Handler\",\n",
    "    instructions=\"You handle standard text requests.\",\n",
    "    model=\"gpt-5-nano\"\n",
    ")\n",
    "\n",
    "orchestrator_agent = Agent(\n",
    "    name=\"Orchestrator\",\n",
    "    instructions=\"\"\"You are a routing assistant. Look at the user's file and instruction. \n",
    "    If they provide an Excel/CSV file AND ask for data analysis or calculations (like finding the mean), reply strictly with the word 'excel'.\n",
    "    For anything else, reply strictly with the word 'text'.\"\"\",\n",
    "    model=\"gpt-5-nano\",\n",
    "    model_settings=ModelSettings(store=False) # Keep it fast and cheap\n",
    ")\n",
    "\n",
    "async def run_workflow(workflow_input: WorkflowInput):\n",
    "    with trace(\"New file workflow\"):\n",
    "        workflow = workflow_input.model_dump()\n",
    "        \n",
    "        # 1. Format the memory\n",
    "        conversation_history: list[TResponseInputItem] = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"input_text\",\n",
    "                        \"text\": f\"File: {workflow['file_path']}\\nInstruction: {workflow['instruction']}\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # --- NEW: The AI Orchestrator makes the decision ---\n",
    "        orchestrator_result = await Runner.run(\n",
    "            orchestrator_agent,\n",
    "            input=[*conversation_history]\n",
    "        )\n",
    "        \n",
    "        # Clean up the output to find the exact word\n",
    "        decision = orchestrator_result.final_output_as(str).strip().lower()\n",
    "\n",
    "        # Route based on the AI's understanding of the text\n",
    "        if \"excel\" in decision:\n",
    "            selected_agent = excel_agent\n",
    "        else:\n",
    "            selected_agent = text_agent\n",
    "\n",
    "        # --- Run the selected agent ---\n",
    "        my_agent_result_temp = await Runner.run(\n",
    "            selected_agent,\n",
    "            input=[*conversation_history],\n",
    "            run_config=RunConfig(trace_metadata={\n",
    "                \"__trace_source__\": \"agent-builder\"\n",
    "            })\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"handled_by\": selected_agent.name,\n",
    "            \"output\": my_agent_result_temp.final_output_as(str)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8e311f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.120082586642795\n"
     ]
    }
   ],
   "source": [
    "input = WorkflowInput(instruction=\"Please take the file and calculate the mean of the first column\" , file_path=\"example.xlsx\")\n",
    "\n",
    "result = await run_workflow(input)\n",
    "\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cb5b114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚙️ THE AGENT IS RUNNING THIS CODE:\n",
      "import pandas as pd\n",
      "# Load\n",
      "df = pd.read_excel('example.xlsx')\n",
      "\n",
      "# Clean: remove columns that are completely empty\n",
      "df = df.dropna(axis=1, how='all')\n",
      "\n",
      "# Fix visual blanks in Category by forward filling\n",
      "if 'Category' in df.columns:\n",
      "    df['Category'] = df['Category'].ffill()\n",
      "\n",
      "# Normalize Amount to numeric\n",
      "if 'Amount' in df.columns:\n",
      "    df['Amount'] = pd.to_numeric(df['Amount'], errors='coerce')\n",
      "\n",
      "# Parse Date Registered to datetime if present\n",
      "if 'Date Registered' in df.columns:\n",
      "    df['Date Registered'] = pd.to_datetime(df['Date Registered'], errors='coerce')\n",
      "\n",
      "# Drop any rows that are completely empty\n",
      "df = df.dropna(how='all')\n",
      "\n",
      "# Save cleaned data\n",
      "df.to_excel('cleaned_example.xlsx', index=False)\n",
      "\n",
      "# Print a quick preview\n",
      "print('Cleaned DataFrame preview (first 5 rows):')\n",
      "print(df.head())\n",
      "\n",
      "# Confirm file saved\n",
      "import os\n",
      "print('File saved:', os.path.exists('cleaned_example.xlsx'))\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "⚙️ THE AGENT IS RUNNING THIS CODE:\n",
      "# Step 3: Compute totals per category from cleaned data\n",
      "summary = df.groupby('Category', as_index=False)['Amount'].sum()\n",
      "print('Total Amount per Category:')\n",
      "print(summary)\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "All steps completed in the requested order.\n",
      "\n",
      "1) Load and clean (visual blanks and useless columns)\n",
      "- File analyzed: example.xlsx\n",
      "- Structure observed from profile:\n",
      "  - Columns: Category, Amount, Date Registered\n",
      "  - Missing values: Category (3), Date Registered (4), Amount (0)\n",
      "  - Visual pattern: Category cells are sometimes blank in consecutive rows (used for grouping)\n",
      "- Cleaning performed:\n",
      "  - Dropped columns that were completely empty (if any)\n",
      "  - Forward-filled the Category column to propagate the category label to rows where it was visually blank\n",
      "  - Converted Date Registered to datetime (NaT for missing values)\n",
      "  - Dropped any rows that were completely empty\n",
      "- Result: Cleaned DataFrame saved to cleaned_example.xlsx via the CRITICAL step 2\n",
      "- Preview of cleaned data (first 5 rows):\n",
      "  - Row 0: Category A, Amount 100, Date Registered NaT\n",
      "  - Row 1: Category A, Amount 150, Date Registered NaT\n",
      "  - Row 2: Category A, Amount 200, Date Registered 2023-01-01\n",
      "  - Row 3: Category B, Amount 50, Date Registered NaT\n",
      "  - Row 4: Category B, Amount 75, Date Registered NaT\n",
      "\n",
      "2) Save cleaned dataframe to disk (CRITICAL)\n",
      "- The code executed df.to_excel('cleaned_example.xlsx', index=False) as part of the cleaning step.\n",
      "- File saved confirmation: File exists on disk (cleaned_example.xlsx) = True\n",
      "\n",
      "3) Calculate total sum of Amount by Category\n",
      "- Totals computed from the cleaned data:\n",
      "  - Category A: 450\n",
      "  - Category B: 125\n",
      "\n",
      "4) Confirm file save\n",
      "- Confirmation: cleaned_example.xlsx was saved successfully to the working directory (confirmed by the file existence check in the Python run).\n",
      "\n",
      "What’s in the cleaned file and results\n",
      "- Cleaned file: cleaned_example.xlsx\n",
      "- Quirks fixed:\n",
      "  - Visual blanks in Category were resolved by forward-filling, producing a proper category per row\n",
      "  - Date Registered values converted to datetime (NaT for missing)\n",
      "  - Removed any completely empty columns/rows\n",
      "- Final category totals (from the cleaned data):\n",
      "  - Category A: 450\n",
      "  - Category B: 125\n",
      "\n",
      "If you’d like, I can also export the totals as JSON, CSV, or adjust the cleaning rules (e.g., drop records with missing Amount, or keep NaN categories).\n",
      "\n",
      "⚙️ THE AGENT IS RUNNING THIS CODE:\n",
      "import pandas as pd\n",
      "\n",
      "# Load the file\n",
      "try:\n",
      "    df = pd.read_excel('example.xlsx')\n",
      "except Exception as e:\n",
      "    raise SystemExit(f'Failed to load file: {e}')\n",
      "\n",
      "# Clean: remove visual blanks and useless columns\n",
      "# Drop a column if it exists but is largely useless. In this dataset, Date Registered is not needed for the aggregation.\n",
      "if 'Date Registered' in df.columns:\n",
      "    df = df.drop(columns=['Date Registered'])\n",
      "\n",
      "# Forward-fill the Category column to propagate group labels downwards\n",
      "if 'Category' in df.columns:\n",
      "    df['Category'] = df['Category'].ffill()\n",
      "\n",
      "# Ensure Amount is numeric\n",
      "if 'Amount' in df.columns:\n",
      "    df['Amount'] = pd.to_numeric(df['Amount'], errors='coerce')\n",
      "\n",
      "# Save the cleaned dataframe to disk (required by instruction)\n",
      "df.to_excel('cleaned_example.xlsx', index=False)\n",
      "\n",
      "# Calculate total sum of Amount per Category\n",
      "category_sums = df.groupby('Category', as_index=False)['Amount'].sum()\n",
      "\n",
      "print('Cleaned dataframe saved to cleaned_example.xlsx')\n",
      "print('Category sums:')\n",
      "print(category_sums.to_string(index=False))\n",
      "\n",
      "# Also print a small preview of the cleaned dataframe for verification\n",
      "print('\\nPreview of cleaned dataframe (first 10 rows):')\n",
      "print(df.head(10).to_string(index=False))\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Here’s what I did in the exact order you requested, using the provided file example.xlsx.\n",
      "\n",
      "1) Data structure and quirks (as loaded)\n",
      "- Columns detected: Category, Amount, Date Registered\n",
      "- Missing values: Category has 3 missing; Date Registered has 4 missing\n",
      "- Visual layout (first 5 rows):\n",
      "  - Row 0: Category A, Amount 100, Date Registered NaN\n",
      "  - Row 1: Category NaN, Amount 150, Date Registered NaN\n",
      "  - Row 2: Category NaN, Amount 200, Date Registered 2023-01-01\n",
      "  - Row 3: Category B, Amount 50, Date Registered NaN\n",
      "  - Row 4: Category NaN, Amount 75, Date Registered NaN\n",
      "- Quirks identified:\n",
      "  - Visual blanks in Category (need forward-fill to group rows)\n",
      "  - Date Registered is not needed for the requested calculation (a “useless” column for this task)\n",
      "\n",
      "2) Cleaning and saving the cleaned file (CRITICAL: saved via execute_python)\n",
      "- Actions taken:\n",
      "  - Dropped the Date Registered column (useless for this task)\n",
      "  - Forward-filled Category to propagate the group labels down the rows\n",
      "  - Ensured Amount is numeric\n",
      "  - Saved the cleaned dataframe to disk as cleaned_example.xlsx (without index)\n",
      "- Result: cleaned_example.xlsx was saved successfully\n",
      "\n",
      "3) Amount sums by Category\n",
      "- Computed total Amount per Category on the cleaned data\n",
      "- Category A: 450\n",
      "- Category B: 125\n",
      "\n",
      "4) Confirmation of file save\n",
      "- The run confirmed: Cleaned dataframe saved to cleaned_example.xlsx\n",
      "- A brief preview of the cleaned data (first rows) shows:\n",
      "  - Category A, 100\n",
      "  - Category A, 150\n",
      "  - Category A, 200\n",
      "  - Category B, 50\n",
      "  - Category B, 75\n",
      "\n",
      "Summary of what was in the file and what was fixed\n",
      "- Original file contained Category, Amount, and Date Registered with visual blanks in Category and sporadic dates.\n",
      "- Fixed by:\n",
      "  - Dropping Date Registered (not needed for the requested calculation)\n",
      "  - Forward-filling Category to remove the visual gaps and enable correct grouping\n",
      "  - Ensuring Amount is numeric\n",
      "- Cleaned file saved as cleaned_example.xlsx in the working directory\n",
      "- Final requested result (sum of Amount per Category):\n",
      "  - Category A: 450\n",
      "  - Category B: 125\n",
      "\n",
      "If you’d like, I can keep Date Registered (with a more targeted imputation strategy), or preserve all columns in the cleaned file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import io\n",
    "import traceback\n",
    "import asyncio\n",
    "from pydantic import BaseModel\n",
    "from agents import Agent, ModelSettings, TResponseInputItem, Runner, RunConfig, trace, function_tool\n",
    "from openai.types.shared.reasoning import Reasoning\n",
    "\n",
    "# ==========================================\n",
    "# 0. SETUP: Create a messy test file\n",
    "# ==========================================\n",
    "# This creates an Excel file with blanks (visual hierarchy) and a mostly empty column\n",
    "df_mock = pd.DataFrame({\n",
    "    \"Category\": [\"Category A\", None, None, \"Category B\", None],\n",
    "    \"Amount\": [100, 150, 200, 50, 75],\n",
    "    \"Date Registered\": [None, None, \"2023-01-01\", None, None]\n",
    "})\n",
    "df_mock.to_excel(\"example.xlsx\", index=False)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 1. BLUEPRINT & STATE\n",
    "# ==========================================\n",
    "class WorkflowInput(BaseModel):\n",
    "    file_path: str\n",
    "    instruction: str\n",
    "\n",
    "# Persistent memory for the Python interpreter\n",
    "_agent_memory_state = {\n",
    "    \"pd\": pd  # Pre-load pandas so the agent doesn't have to import it\n",
    "}\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 2. THE TOOLS\n",
    "# ==========================================\n",
    "@function_tool\n",
    "def profile_excel_structure(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyzes an Excel file and returns a summary of its structure, missing values, and a sample of the data.\n",
    "    Use this FIRST to understand how the user formatted the sheet before trying to clean or calculate anything.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        missing_data = df.isnull().sum().to_string()\n",
    "        sample_data = df.head(15).to_string()\n",
    "        \n",
    "        report = (\n",
    "            f\"--- COLUMNS & MISSING VALUES ---\\n{missing_data}\\n\\n\"\n",
    "            f\"--- FIRST 15 ROWS (VISUAL LAYOUT) ---\\n{sample_data}\"\n",
    "        )\n",
    "        return report\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {str(e)}\"\n",
    "\n",
    "@function_tool\n",
    "def execute_python(code_string: str) -> str:\n",
    "    \"\"\"\n",
    "    Executes Python code in a persistent stateful environment. \n",
    "    Variables created in one call (like 'df') will be available in the next call.\n",
    "    ALWAYS use print() to output the final result or preview of the dataframe so you can see it.\n",
    "    \n",
    "    Args:\n",
    "        code_string (str): The Python code to execute.\n",
    "    \"\"\"\n",
    "    # --- ADD THESE THREE LINES ---\n",
    "    print(\"\\n⚙️ THE AGENT IS RUNNING THIS CODE:\")\n",
    "    print(code_string)\n",
    "    print(\"----------------------------------\\n\")\n",
    "\n",
    "    old_stdout = sys.stdout\n",
    "    redirected_output = sys.stdout = io.StringIO()\n",
    "    \n",
    "    try:\n",
    "        exec(code_string, _agent_memory_state)\n",
    "        output = redirected_output.getvalue().strip()\n",
    "        \n",
    "        if not output:\n",
    "            return \"Code executed successfully, but nothing was printed. Did you forget to print() the result?\"\n",
    "        return f\"Output:\\n{output}\"\n",
    "        \n",
    "    except Exception:\n",
    "        error_msg = traceback.format_exc()\n",
    "        return f\"Error executing code:\\n{error_msg}\"\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. THE AGENT\n",
    "# ==========================================\n",
    "data_analyst_agent = Agent(\n",
    "    name=\"Data Analyst\",\n",
    "    instructions=\"\"\"You are an autonomous Data Analyst. \n",
    "    When given a file and an instruction:\n",
    "    1. ALWAYS run `profile_excel_structure` first to see the data format.\n",
    "    2. Identify human formatting quirks (like blanks used for visual grouping, or useless mostly-empty columns).\n",
    "    3. Use `execute_python` to write pandas code that loads the file into a variable named `df`, cleans those quirks, and performs the user's requested instruction.\n",
    "    4. Provide a final summary of what the file contained, what quirks you fixed, and the final answer to the user's instruction.\"\"\",\n",
    "    model=\"gpt-5-nano\",\n",
    "    model_settings=ModelSettings(store=True, reasoning=Reasoning(effort=\"high\")),\n",
    "    tools=[profile_excel_structure, execute_python]\n",
    ")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 4. THE WORKFLOW\n",
    "# ==========================================\n",
    "async def run_workflow(workflow_input: WorkflowInput):\n",
    "    with trace(\"Data Analysis Workflow\"):\n",
    "        workflow = workflow_input.model_dump()\n",
    "        \n",
    "        conversation_history: list[TResponseInputItem] = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"input_text\",\n",
    "                        \"text\": f\"File: {workflow['file_path']}\\nInstruction: {workflow['instruction']}\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        my_agent_result_temp = await Runner.run(\n",
    "            data_analyst_agent,\n",
    "            input=[*conversation_history],\n",
    "            run_config=RunConfig(trace_metadata={\n",
    "                \"__trace_source__\": \"agent-builder\"\n",
    "            })\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"output\": my_agent_result_temp.final_output_as(str)\n",
    "        }\n",
    "\n",
    "# ==========================================\n",
    "# 5. EXECUTION\n",
    "# ==========================================\n",
    "strict_instruction = \"\"\"\n",
    "You must complete the following steps in this exact order:\n",
    "1. Load the file and clean up the visual blanks and useless columns.\n",
    "2. CRITICAL: You must use the execute_python tool to run `df.to_excel('cleaned_example.xlsx', index=False)` to save the cleaned dataframe to the disk.\n",
    "3. Calculate the total sum of the Amount column for each Category.\n",
    "4. Confirm in your final response that the new file was successfully saved.\n",
    "\"\"\"\n",
    "\n",
    "input_data = WorkflowInput(\n",
    "    file_path=\"example.xlsx\", \n",
    "    instruction=strict_instruction\n",
    ")\n",
    "\n",
    "result = await run_workflow(input_data)\n",
    "print(result[\"output\"])\n",
    "\n",
    "# Await the execution (assumes Jupyter Notebook environment)\n",
    "result = await run_workflow(input_data)\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abfa352",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
