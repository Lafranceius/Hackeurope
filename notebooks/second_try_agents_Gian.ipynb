{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d8e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "class ColumnTypes(BaseModel):\n",
    "    types: list[str]\n",
    "\n",
    "def reader_agent(file_path: str) -> list[str]:\n",
    "    print(f\"Orchestrator: Reading {file_path}...\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {e}\"\n",
    "\n",
    "    sample_data = df.head(5).to_dict(orient=\"list\")\n",
    "    print(\"Orchestrator: Passing sample to Reader Agent...\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following data sample from an Excel file.\n",
    "    For each column, determine its data type based on the values.\n",
    "    You must return a list where each element corresponds to a column from left to right.\n",
    "    \n",
    "    You are ONLY allowed to use these exact categories: \"time\", \"money\", \"int\", \"string\", \"float\".\n",
    "    \n",
    "    CRITICAL DEFINITIONS:\n",
    "    - \"time\": Includes standard formats (2023-01-01, 14:30), timestamps, AND natural language dates (e.g., \"first of january 2016\", \"Q1 2024\", \"yesterday\"). If the core meaning represents a date or time, it is \"time\", NEVER \"string\".\n",
    "    - \"money\": Includes currency symbols ($100, €50), accounting formats, or financial abbreviations (100 USD) and natural language money expressions (\"100 dollars\", \"fifty euros\"). If the core meaning represents a monetary value, it is \"money\", NEVER \"string\".\n",
    "    - \"int\": Whole numbers without decimals.\n",
    "    - \"float\": Numbers containing decimals.\n",
    "    - \"string\": General text, names, or categories that do not fit the above.\n",
    "\n",
    "    Data sample (Columns and their first 5 values):\n",
    "    {sample_data}\n",
    "    \"\"\"\n",
    "\n",
    "    # We use the .parse() method to guarantee the output matches our ColumnTypes class\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-2024-08-06\", # Structured outputs work best on newer models\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a precise data analysis agent.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=ColumnTypes\n",
    "    )\n",
    "\n",
    "    # Extract the clean vector from the response\n",
    "    type_vector = response.choices[0].message.parsed.types\n",
    "    return type_vector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0810c629",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "   # Create a quick dummy file to test the agent\n",
    "    dummy_df = pd.DataFrame({\n",
    "        \"Date\": [\"Jan 1st 2013\", \"January second 2013\"],\n",
    "        \"Revenue\": [\"100.50 dollars\", \"200.00 dollars\"],\n",
    "        \"Count\": [5, 10],\n",
    "        \"Name\": [\"Alice\", \"BOB\"],\n",
    "        \"Multiplier\": [1.5, 2.3]\n",
    "    })\n",
    "    dummy_df.to_excel(\"test_reader.xlsx\", index=False)\n",
    "\n",
    "    # Run the block\n",
    "    resulting_vector = reader_agent(\"test_reader.xlsx\")\n",
    "    \n",
    "    print(\"\\n--- FINAL VECTOR ---\")\n",
    "    print(resulting_vector)\n",
    "    # Expected output: ['time', 'money', 'int', 'string', 'float']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11d411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import dateparser\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "class ColumnTypes(BaseModel):\n",
    "    types: list[str]\n",
    "\n",
    "def reader_agent(file_path: str) -> list[str]:\n",
    "    print(f\"[Reader Agent] Reading '{file_path}' to classify columns...\")\n",
    "    df = pd.read_excel(file_path)\n",
    "    sample_data = df.head(5).to_dict(orient=\"list\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following data sample from an Excel file.\n",
    "    For each column, determine its data type based on the values.\n",
    "    You must return a list where each element corresponds to a column from left to right.\n",
    "    \n",
    "    You are ONLY allowed to use these exact categories: \"time\", \"money\", \"int\", \"string\", \"float\", \"name\", \"unknown\".\n",
    "    \n",
    "    CRITICAL DEFINITIONS:\n",
    "    - \"time\": Includes standard formats (2023-01-01, 14:30), timestamps, AND natural language dates (e.g., \"first of january 2016\", \"Q1 2024\", \"yesterday\"). If the core meaning represents a date or time, it is \"time\", NEVER \"string\".\n",
    "    - \"money\": Includes currency symbols ($100, €50), accounting formats, or financial abbreviations (100 USD) and natural language money expressions (\"100 dollars\", \"fifty euros\"). If the core meaning represents a monetary value, it is \"money\", NEVER \"string\".\n",
    "    - \"int\": Whole numbers without decimals.\n",
    "    - \"float\": Numbers containing decimals.\n",
    "    - \"name\": Proper nouns. This includes human names (John Smith, Smith, John), cities, states (Alabama), or company names.\n",
    "    - \"string\": General text, sentences, descriptions, or specific codes (e.g., ID-4552) that have no mathematical or temporal value.\n",
    "    - \"unknown\": Use this ONLY if the column is complete gibberish or you cannot confidently assign it to any other category.\n",
    "\n",
    "    Data sample (Columns and their first 5 values):\n",
    "    {sample_data}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a precise data analysis agent.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=ColumnTypes\n",
    "    )\n",
    "    \n",
    "    vector = response.choices[0].message.parsed.types\n",
    "    print(f\"[Reader Agent] Classification complete: {vector}\")\n",
    "    return vector\n",
    "\n",
    "class TimeFormatDecision(BaseModel):\n",
    "    reasoning: str\n",
    "    target_format: Literal[\n",
    "        \"%H:%M\", \"%H:%M:%S\", \"%S\", \n",
    "        \"%d/%m/%Y\", \"%d/%m/%Y %H:%M\", \"%d/%m/%Y %H:%M:%S\", \n",
    "        \"%m/%Y\", \"%Y\"\n",
    "    ]\n",
    "\n",
    "def execute_time_formatting(df: pd.DataFrame, col_name: str, target_format: str) -> pd.DataFrame:\n",
    "    \"\"\"The Tool used to physically alter the dataframe.\"\"\"\n",
    "    print(f\"       [Tool Executing] Formatting '{col_name}' to '{target_format}'...\")\n",
    "    \n",
    "    def parse_natural_language(date_str):\n",
    "        if pd.isna(date_str):\n",
    "            return pd.NaT\n",
    "            \n",
    "        clean_str = str(date_str).lower()\n",
    "        replacements = {\n",
    "            \"first\": \"1st\", \"second\": \"2nd\", \"third\": \"3rd\", \n",
    "            \"fourth\": \"4th\", \"fifth\": \"5th\", \"sixth\": \"6th\", \n",
    "            \"seventh\": \"7th\", \"eighth\": \"8th\", \"ninth\": \"9th\", \n",
    "            \"tenth\": \"10th\", \"eleventh\": \"11th\", \"twelfth\": \"12th\", \n",
    "            \"thirteenth\": \"13th\", \"fourteenth\": \"14th\", \"fifteenth\": \"15th\", \n",
    "            \"sixteenth\": \"16th\", \"seventeenth\": \"17th\", \"eighteenth\": \"18th\", \n",
    "            \"nineteenth\": \"19th\", \"twentieth\": \"20th\",\n",
    "            \"twenty-first\": \"21st\", \"twenty first\": \"21st\",\n",
    "            \"twenty-second\": \"22nd\", \"twenty second\": \"22nd\",\n",
    "            \"twenty-third\": \"23rd\", \"twenty third\": \"23rd\",\n",
    "            \"twenty-fourth\": \"24th\", \"twenty fourth\": \"24th\",\n",
    "            \"twenty-fifth\": \"25th\", \"twenty fifth\": \"25th\",\n",
    "            \"twenty-sixth\": \"26th\", \"twenty sixth\": \"26th\",\n",
    "            \"twenty-seventh\": \"27th\", \"twenty seventh\": \"27th\",\n",
    "            \"twenty-eighth\": \"28th\", \"twenty eighth\": \"28th\",\n",
    "            \"twenty-ninth\": \"29th\", \"twenty ninth\": \"29th\",\n",
    "            \"thirtieth\": \"30th\", \n",
    "            \"thirty-first\": \"31st\", \"thirty first\": \"31st\",\n",
    "            \"last\": \"last\"\n",
    "        }\n",
    "        for word, num in replacements.items():\n",
    "            clean_str = clean_str.replace(word, num)\n",
    "            \n",
    "        parsed = dateparser.parse(clean_str)\n",
    "        return parsed if parsed else pd.NaT\n",
    "\n",
    "    try:\n",
    "        df[col_name] = df[col_name].apply(parse_natural_language)\n",
    "        df[col_name] = df[col_name].dt.strftime(target_format)\n",
    "        print(f\"       [Tool Success] Column updated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"       [Tool Error] Failed: {e}\")\n",
    "    return df\n",
    "\n",
    "def time_agent_workflow(df: pd.DataFrame, col_name: str) -> pd.DataFrame:\n",
    "    print(f\"  -> [Time Agent] Taking control of column: '{col_name}'\")\n",
    "    sample_data = df[col_name].dropna().head(5).tolist()\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Look at this sample of time/date data from the column '{col_name}'.\n",
    "    Data sample: {sample_data}\n",
    "    \n",
    "    Determine the appropriate standardized format for this data based on its granularity.\n",
    "    - Hours and minutes: \"%H:%M\"\n",
    "    - Hours, minutes, and seconds: \"%H:%M:%S\"\n",
    "    - Just seconds: \"%S\"\n",
    "    - Specific dates: \"%d/%m/%Y\"\n",
    "    - Date and time: \"%d/%m/%Y %H:%M\"\n",
    "    - Date and exact time: \"%d/%m/%Y %H:%M:%S\"\n",
    "    - Month and year: \"%m/%Y\"\n",
    "    - Year only: \"%Y\"\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert data formatting agent.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=TimeFormatDecision\n",
    "    )\n",
    "    \n",
    "    decision = response.choices[0].message.parsed\n",
    "    print(f\"     [Time Agent Decision] {decision.reasoning}\")\n",
    "    \n",
    "    df = execute_time_formatting(df, col_name, decision.target_format)\n",
    "    return df\n",
    "\n",
    "\n",
    "def orchestrator_router(file_path: str, type_vector: list[str]):\n",
    "    print(f\"\\n[Orchestrator] Loading '{file_path}' and delegating tasks...\")\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    for col_name, col_type in zip(df.columns, type_vector):\n",
    "        if col_type == \"time\":\n",
    "            df = time_agent_workflow(df, col_name)\n",
    "        elif col_type == \"money\":\n",
    "            df = money_agent_workflow(df, col_name) \n",
    "        elif col_type == \"int\":\n",
    "            df = int_agent_workflow(df, col_name)\n",
    "        elif col_type == \"name\":\n",
    "            df = name_agent_workflow(df, col_name)\n",
    "        elif col_type in [\"string\", \"unknown\"]:\n",
    "            print(f\"  -> [Orchestrator] Bypassing '{col_name}' (Type: {col_type} requires no formatting)\")\n",
    "\n",
    "    \n",
    "    output_path = \"cleaned_\" + file_path\n",
    "    df.to_excel(output_path, index=False)\n",
    "    print(f\"\\n[Orchestrator] All tasks complete. Saved new file to: {output_path}\")\n",
    "\n",
    "\n",
    "class MoneyFormatDecision(BaseModel):\n",
    "    reasoning: str\n",
    "    is_mixed_currency: bool  \n",
    "    detected_currency: str   \n",
    "    scale_decision: Literal[\"None\", \"Thousands\", \"Millions\", \"Billions\"]\n",
    "    decimal_separator: Literal[\".\", \",\"]\n",
    "\n",
    "\n",
    "def execute_money_formatting(df: pd.DataFrame, col_name: str, decision: MoneyFormatDecision) -> pd.DataFrame:\n",
    "    print(f\"       [Tool Executing] Scale: {decision.scale_decision}, Mixed Currency: {decision.is_mixed_currency}...\")\n",
    "    \n",
    "    def parse_money_string(val):\n",
    "        if pd.isna(val):\n",
    "            return pd.NA, \"\"\n",
    "            \n",
    "        val_str = str(val).lower().strip()\n",
    "        original_str = str(val).strip() \n",
    "        \n",
    "        # 1. Extract the currency symbol, code, or full word\n",
    "        # We expanded the regex to look for words like \"dollars\" and \"euros\"\n",
    "        symbol_match = re.search(r'([\\$€£¥]|(?:usd|eur|gbp|jpy|dollars?|euros?|pounds?|yen))', original_str, re.IGNORECASE)\n",
    "        raw_symbol = symbol_match.group(1).lower() if symbol_match else \"\"\n",
    "        \n",
    "        # 2. Normalize the currency so \"dollars\" and \"$\" both become \"USD\"\n",
    "        currency_map = {\n",
    "            \"dollar\": \"USD\", \"dollars\": \"USD\", \"$\": \"USD\", \"usd\": \"USD\",\n",
    "            \"euro\": \"EUR\", \"euros\": \"EUR\", \"eur\": \"EUR\", \"€\": \"EUR\",\n",
    "            \"pound\": \"GBP\", \"pounds\": \"GBP\", \"gbp\": \"GBP\", \"£\": \"GBP\",\n",
    "            \"yen\": \"JPY\", \"jpy\": \"JPY\", \"¥\": \"JPY\"\n",
    "        }\n",
    "        # Get the standard code, or just uppercase it if it's not in the map\n",
    "        symbol = currency_map.get(raw_symbol, raw_symbol.upper())\n",
    "        \n",
    "        # 3. Handle International Decimals\n",
    "        if decision.decimal_separator == \",\":\n",
    "            val_str = val_str.replace('.', '').replace(',', '.')\n",
    "        else:\n",
    "            val_str = val_str.replace(',', '')\n",
    "            \n",
    "        # DEFENSIVE SHIELD: Remove extra dots\n",
    "        if val_str.count('.') > 1:\n",
    "            parts = val_str.rsplit('.', 1)\n",
    "            val_str = parts[0].replace('.', '') + '.' + parts[1]\n",
    "            \n",
    "        # 4. Extract the core number\n",
    "        match = re.search(r'[\\d\\.]+', val_str)\n",
    "        if not match:\n",
    "            return pd.NA, symbol\n",
    "        try:\n",
    "            num = float(match.group())\n",
    "        except ValueError:\n",
    "            return pd.NA, symbol\n",
    "            \n",
    "        # 5. Apply word multipliers\n",
    "        isolated_words = re.sub(r'[\\d\\.\\,€\\$£¥]', ' ', val_str).split()\n",
    "        \n",
    "        if any(w in isolated_words for w in ['billion', 'billions', 'bill', 'bil', 'b']):\n",
    "            num *= 1_000_000_000\n",
    "        elif any(w in isolated_words for w in ['million', 'millions', 'mill', 'mil', 'm']):\n",
    "            num *= 1_000_000\n",
    "        elif any(w in isolated_words for w in ['thousand', 'thousands', 'k']):\n",
    "            num *= 1_000\n",
    "        elif any(w in isolated_words for w in ['cent', 'cents']):\n",
    "            num /= 100\n",
    "            \n",
    "        return num, symbol\n",
    "\n",
    "    try:\n",
    "        # Get a list of (number, symbol) tuples for every row\n",
    "        parsed_data = df[col_name].apply(parse_money_string)\n",
    "        \n",
    "        # Separate the numbers and symbols into two lists\n",
    "        nums = [x[0] if isinstance(x, tuple) else pd.NA for x in parsed_data]\n",
    "        symbols = [x[1] if isinstance(x, tuple) else \"\" for x in parsed_data]\n",
    "        \n",
    "        df[col_name] = nums\n",
    "        \n",
    "        # 5. Apply the Scale Decision\n",
    "        scale_suffix = \"\"\n",
    "        if decision.scale_decision == \"Billions\":\n",
    "            df[col_name] = df[col_name] / 1_000_000_000\n",
    "            scale_suffix = \"in billions\"\n",
    "        elif decision.scale_decision == \"Millions\":\n",
    "            df[col_name] = df[col_name] / 1_000_000\n",
    "            scale_suffix = \"in millions\"\n",
    "        elif decision.scale_decision == \"Thousands\":\n",
    "            df[col_name] = df[col_name] / 1_000\n",
    "            scale_suffix = \"in thousands\"\n",
    "\n",
    "        # 6. Final Formatting: Mixed vs Single Currency\n",
    "        if decision.is_mixed_currency:\n",
    "            # Re-attach the symbol to the number (converts back to string)\n",
    "            def reattach(row_num, row_sym):\n",
    "                if pd.isna(row_num):\n",
    "                    return pd.NA\n",
    "                return f\"{row_sym} {row_num}\".strip()\n",
    "            \n",
    "            df[col_name] = [reattach(n, s) for n, s in zip(df[col_name], symbols)]\n",
    "            \n",
    "            # Rename column if scaling was applied\n",
    "            if scale_suffix:\n",
    "                new_col_name = f\"{col_name} ({scale_suffix})\"\n",
    "                df.rename(columns={col_name: new_col_name}, inplace=True)\n",
    "                print(f\"       [Tool Success] Mixed currencies kept in cells. Renamed to '{new_col_name}'.\")\n",
    "                \n",
    "        else:\n",
    "            # Single currency: Keep as floats, put currency in the header\n",
    "            parts = []\n",
    "            if decision.detected_currency and decision.detected_currency != \"Unknown\":\n",
    "                parts.append(decision.detected_currency)\n",
    "            if scale_suffix:\n",
    "                parts.append(scale_suffix)\n",
    "                \n",
    "            if parts:\n",
    "                header_addition = \" \".join(parts) # e.g., \"USD in millions\"\n",
    "                new_col_name = f\"{col_name} ({header_addition})\"\n",
    "                df.rename(columns={col_name: new_col_name}, inplace=True)\n",
    "                print(f\"       [Tool Success] Floats extracted. Renamed to '{new_col_name}'.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"       [Tool Error] Failed: {e}\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "def money_agent_workflow(df: pd.DataFrame, col_name: str) -> pd.DataFrame:\n",
    "    print(f\"  -> [Money Agent] Taking control of column: '{col_name}'\")\n",
    "    sample_data = df[col_name].dropna().head(10).tolist()\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Look at this sample of financial data from the column '{col_name}'.\n",
    "    Data sample: {sample_data}\n",
    "    \n",
    "    Your task:\n",
    "    1. Identify the primary currency being used (e.g., $, USD, €, Yen, \"dollars\", \"euros\"). \n",
    "       - CRITICAL RULE: If a currency is specified even just once in the sample, and NO OTHER currencies are mentioned, assume that single currency applies to the entire column.\n",
    "    2. Set `is_mixed_currency` to True ONLY if you see multiple DIFFERENT currencies (e.g., \"dollars\" in one row and \"eur\" in another).\n",
    "    3. Determine the best scale (\"None\", \"Thousands\", \"Millions\", \"Billions\").\n",
    "       - Evaluate the TRUE underlying numerical value. \"100 million\" means 100,000,000. \n",
    "       - If the true values are predominantly in the millions, you MUST choose \"Millions\".\n",
    "    4. Identify the decimal separator used in the numbers (\".\" or \",\").\n",
    "       - WARNING: Commas that group thousands (like \"200,000,000\") are NOT decimal separators. If a comma groups thousands, the decimal separator is \".\".\n",
    "       - Only choose \",\" if the comma specifically separates fractional cents at the very end of the number (e.g., \"1.500,00\").\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a precise financial data standardization agent.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=MoneyFormatDecision\n",
    "    )\n",
    "    \n",
    "    decision = response.choices[0].message.parsed\n",
    "    print(f\"     [Money Agent Decision] Mixed: {decision.is_mixed_currency} | Currency: {decision.detected_currency} | Scale: {decision.scale_decision}\")\n",
    "    \n",
    "    df = execute_money_formatting(df, col_name, decision)\n",
    "    return df\n",
    "\n",
    "\n",
    "def execute_int_formatting(df: pd.DataFrame, col_name: str) -> pd.DataFrame:\n",
    "    print(f\"       [Tool Executing] Cleaning and truncating '{col_name}' to integers...\")\n",
    "    \n",
    "    def parse_int(val):\n",
    "        if pd.isna(val):\n",
    "            return pd.NA\n",
    "            \n",
    "        val_str = str(val).lower().replace(',', '').strip()\n",
    "        \n",
    "        try:\n",
    "            num = float(val_str)\n",
    "            return int(num)\n",
    "        except ValueError:\n",
    "            return pd.NA\n",
    "\n",
    "    try:\n",
    "        df[col_name] = df[col_name].apply(parse_int)\n",
    "        df[col_name] = df[col_name].astype('Int64')\n",
    "        \n",
    "        print(f\"       [Tool Success] Column '{col_name}' safely truncated to integers.\")\n",
    "    except Exception as e:\n",
    "        print(f\"       [Tool Error] Failed to process integers: {e}\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "def int_agent_workflow(df: pd.DataFrame, col_name: str) -> pd.DataFrame:\n",
    "    print(f\"  -> [Int Agent] Taking control of column: '{col_name}' (Bypassing LLM for deterministic math)\")\n",
    "    \n",
    "    df = execute_int_formatting(df, col_name)\n",
    "    return df\n",
    "\n",
    "def execute_float_formatting(df: pd.DataFrame, col_name: str) -> pd.DataFrame:\n",
    "    print(f\"       [Tool Executing] Standardizing floats for '{col_name}'...\")\n",
    "    \n",
    "    # 1. Clean the data and convert to pure floats\n",
    "    def extract_float(val):\n",
    "        if pd.isna(val):\n",
    "            return pd.NA\n",
    "        val_str = str(val).lower().replace(',', '').strip()\n",
    "        try:\n",
    "            return float(val_str)\n",
    "        except ValueError:\n",
    "            return pd.NA\n",
    "            \n",
    "    raw_floats = df[col_name].apply(extract_float)\n",
    "    \n",
    "    # 2. Determine the maximum number of decimal places in the column\n",
    "    max_decimals = 0\n",
    "    for val in raw_floats.dropna():\n",
    "        # Convert float to string (e.g., 0.876 -> \"0.876\") and split at the dot\n",
    "        parts = str(val).split('.')\n",
    "        if len(parts) == 2:\n",
    "            decimals = len(parts[1])\n",
    "            if max_decimals < decimals:\n",
    "                max_decimals = decimals\n",
    "                \n",
    "    # 3. Format every number to match the max_decimals length\n",
    "    def pad_float(val):\n",
    "        if pd.isna(val):\n",
    "            return pd.NA\n",
    "        # This dynamically creates a format rule like \"{:.3f}\"\n",
    "        return f\"{val:.{max_decimals}f}\"\n",
    "        \n",
    "    df[col_name] = raw_floats.apply(pad_float)\n",
    "    \n",
    "    print(f\"       [Tool Success] Floats standardized to {max_decimals} decimal places.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def float_agent_workflow(df: pd.DataFrame, col_name: str) -> pd.DataFrame:\n",
    "    print(f\"  -> [Float Agent] Taking control of column: '{col_name}' (Bypassing LLM)\")\n",
    "    \n",
    "    df = execute_float_formatting(df, col_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "class NameFormatDecision(BaseModel):\n",
    "    reasoning: str\n",
    "    entity_type: Literal[\"Human Names\", \"Locations/Other\"]\n",
    "    dominant_format: Literal[\"First Last\", \"Last First\", \"N/A\"]\n",
    "\n",
    "\n",
    "def execute_name_formatting(df: pd.DataFrame, col_name: str, decision: NameFormatDecision) -> pd.DataFrame:\n",
    "    print(f\"       [Tool Executing] Cleaning names. Type: {decision.entity_type}, Format: {decision.dominant_format}...\")\n",
    "    \n",
    "    def parse_name(val):\n",
    "        if pd.isna(val):\n",
    "            return pd.NA\n",
    "            \n",
    "        # 1. Standardize capitalization (e.g., \"JOHN smith\" -> \"John Smith\")\n",
    "        clean_name = str(val).strip().title()\n",
    "        \n",
    "        # 2. If it's a Location/Other, we just return the title-cased string\n",
    "        if decision.entity_type == \"Locations/Other\":\n",
    "            return clean_name\n",
    "            \n",
    "        # 3. Handle Human Names\n",
    "        # If there's a comma (e.g., \"Smith, John\"), split it and force \"First Last\"\n",
    "        if \",\" in clean_name:\n",
    "            parts = [p.strip() for p in clean_name.split(\",\")]\n",
    "            if len(parts) == 2:\n",
    "                return f\"{parts[1]} {parts[0]}\"\n",
    "                \n",
    "        # If the LLM determined the column is mostly \"Last First\" without commas (e.g., \"Smith John\")\n",
    "        if decision.dominant_format == \"Last First\":\n",
    "            parts = clean_name.split()\n",
    "            if len(parts) == 2:\n",
    "                # Flip it to \"First Last\"\n",
    "                return f\"{parts[1]} {parts[0]}\"\n",
    "                \n",
    "        # Default fallback: return as-is (already title-cased)\n",
    "        return clean_name\n",
    "\n",
    "    try:\n",
    "        df[col_name] = df[col_name].apply(parse_name)\n",
    "        print(f\"       [Tool Success] Column '{col_name}' standardized.\")\n",
    "    except Exception as e:\n",
    "        print(f\"       [Tool Error] Failed to process names: {e}\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def name_agent_workflow(df: pd.DataFrame, col_name: str) -> pd.DataFrame:\n",
    "    print(f\"  -> [Name Agent] Taking control of column: '{col_name}'\")\n",
    "    \n",
    "    # Grab 10 rows to give the LLM enough pattern context\n",
    "    sample_data = df[col_name].dropna().head(10).tolist()\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Look at this sample of proper nouns from the column '{col_name}'.\n",
    "    Data sample: {sample_data}\n",
    "    \n",
    "    Your task:\n",
    "    1. Determine if this column primarily contains \"Human Names\" or \"Locations/Other\" (like cities, states, companies).\n",
    "    2. If it is \"Human Names\", deduce the dominant structural format.\n",
    "       - Are they mostly \"First Last\" (e.g., John Smith)?\n",
    "       - Are they mostly \"Last First\" (e.g., Smith John)?\n",
    "       - NOTE: If you see ambiguous names (like \"Harper Taylor\"), look at the other names in the sample to deduce the pattern.\n",
    "    3. If it is \"Locations/Other\", select \"N/A\" for the format.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a precise text standardization agent.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=NameFormatDecision\n",
    "    )\n",
    "    \n",
    "    decision = response.choices[0].message.parsed\n",
    "    print(f\"     [Name Agent Decision] Type: {decision.entity_type} | Dominant Format: {decision.dominant_format}\")\n",
    "    \n",
    "    df = execute_name_formatting(df, col_name, decision)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_file = \"test_pipeline.xlsx\"\n",
    "    pd.DataFrame({\n",
    "        \"Event Date\": [\"first of january 2016\", \"january second 2016\", \"yesterday\"],\n",
    "        \"Revenue\": [\"100 million dollars\", \"200000000\", \"300 mil eur\"],\n",
    "        \"entities\": [5, 10, 15.0],\n",
    "        \"Customer\": [\"Alice\", \"Bob\", \"Charlie SMITH\"]\n",
    "    }).to_excel(test_file, index=False)\n",
    "    \n",
    "    print(\"--- STARTING AGENTIC PIPELINE ---\")\n",
    "\n",
    "    classified_types = reader_agent(test_file)\n",
    "    \n",
    "    orchestrator_router(test_file, classified_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f59d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"first of january 2016\", \"january second 2016\", \"yesterday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f95959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
