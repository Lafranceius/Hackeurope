{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e11d411f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING AGENTIC PIPELINE ---\n",
      "[Reader Agent] Reading 'test_pipeline.xlsx' to classify columns...\n",
      "[Reader Agent] Classification complete: ['time', 'money', 'int', 'name']\n",
      "\n",
      "[Orchestrator] Loading 'test_pipeline.xlsx' and delegating tasks...\n",
      "  -> [Time Agent] Taking control of column: 'Event Date'\n",
      "     [Time Agent Decision] The data sample consists of written dates in a format that specifies the exact day, month, and year. For example, 'first of january 2016' can be interpreted as '01/01/2016', and 'january second 2016' can be interpreted as '02/01/2016'. The term 'yesterday' would need to be converted to an exact date based on the current date context, but it also indicates a specific day recognition in its usage. Therefore, the date information of interest is represented in the day/month/year format. This suggests that the granularity of the data corresponds to specific calendar dates without the need for time information (hours, minutes, or seconds) attached.\n",
      "       [Tool Executing] Formatting 'Event Date' to '%d/%m/%Y'...\n",
      "       [Tool Success] Column updated.\n",
      "  -> [Money Agent] Taking control of column: 'Revenue'\n",
      "     [Money Agent Decision] Mixed: True | Currency:  | Scale: Millions\n",
      "       [Tool Executing] Scale: Millions, Mixed Currency: True...\n",
      "       [Tool Success] Mixed currencies kept in cells. Renamed to 'Revenue (in millions)'.\n",
      "  -> [Int Agent] Taking control of column: 'entities' (Bypassing LLM for deterministic math)\n",
      "       [Tool Executing] Cleaning and truncating 'entities' to integers...\n",
      "       [Tool Success] Column 'entities' safely truncated to integers.\n",
      "  -> [Name Agent] Taking control of column: 'Customer'\n",
      "     [Name Agent Decision] Type: Human Names | Dominant Format: First Last\n",
      "       [Tool Executing] Cleaning names. Type: Human Names, Format: First Last...\n",
      "       [Tool Success] Column 'Customer' standardized.\n",
      "\n",
      "[Orchestrator] All tasks complete. Saved new file to: cleaned_test_pipeline.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import dateparser\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "class ColumnTypes(BaseModel):\n",
    "    types: list[str]\n",
    "\n",
    "def reader_agent(file_path: str) -> list[str]:\n",
    "    print(f\"[Reader Agent] Reading '{file_path}' to classify columns...\")\n",
    "    df = pd.read_excel(file_path)\n",
    "    sample_data = df.head(5).to_dict(orient=\"list\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following data sample from an Excel file.\n",
    "    For each column, determine its data type based on the values.\n",
    "    You must return a list where each element corresponds to a column from left to right.\n",
    "    \n",
    "    You are ONLY allowed to use these exact categories: \"time\", \"money\", \"int\", \"string\", \"float\", \"name\", \"unknown\".\n",
    "    \n",
    "    CRITICAL DEFINITIONS:\n",
    "    - \"time\": Includes standard formats (2023-01-01, 14:30), timestamps, AND natural language dates (e.g., \"first of january 2016\", \"Q1 2024\", \"yesterday\"). If the core meaning represents a date or time, it is \"time\", NEVER \"string\".\n",
    "    - \"money\": Includes currency symbols ($100, €50), accounting formats, or financial abbreviations (100 USD) and natural language money expressions (\"100 dollars\", \"fifty euros\"). If the core meaning represents a monetary value, it is \"money\", NEVER \"string\".\n",
    "    - \"int\": Whole numbers without decimals.\n",
    "    - \"float\": Numbers containing decimals.\n",
    "    - \"name\": Proper nouns. This includes human names (John Smith, Smith, John), cities, states (Alabama), or company names.\n",
    "    - \"string\": General text, sentences, descriptions, or specific codes (e.g., ID-4552) that have no mathematical or temporal value.\n",
    "    - \"unknown\": Use this ONLY if the column is complete gibberish or you cannot confidently assign it to any other category.\n",
    "\n",
    "    Data sample (Columns and their first 5 values):\n",
    "    {sample_data}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a precise data analysis agent.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=ColumnTypes\n",
    "    )\n",
    "    \n",
    "    vector = response.choices[0].message.parsed.types\n",
    "    print(f\"[Reader Agent] Classification complete: {vector}\")\n",
    "    return vector\n",
    "\n",
    "class TimeFormatDecision(BaseModel):\n",
    "    reasoning: str\n",
    "    target_format: Literal[\n",
    "        \"%H:%M\", \"%H:%M:%S\", \"%S\", \n",
    "        \"%d/%m/%Y\", \"%d/%m/%Y %H:%M\", \"%d/%m/%Y %H:%M:%S\", \n",
    "        \"%m/%Y\", \"%Y\"\n",
    "    ]\n",
    "\n",
    "def execute_time_formatting(df: pd.DataFrame, col_name: str, target_format: str) -> pd.DataFrame:\n",
    "    \"\"\"The Tool used to physically alter the dataframe.\"\"\"\n",
    "    print(f\"       [Tool Executing] Formatting '{col_name}' to '{target_format}'...\")\n",
    "    \n",
    "    def parse_natural_language(date_str):\n",
    "        if pd.isna(date_str):\n",
    "            return pd.NaT\n",
    "            \n",
    "        clean_str = str(date_str).lower()\n",
    "        replacements = {\n",
    "            \"first\": \"1st\", \"second\": \"2nd\", \"third\": \"3rd\", \n",
    "            \"fourth\": \"4th\", \"fifth\": \"5th\", \"sixth\": \"6th\", \n",
    "            \"seventh\": \"7th\", \"eighth\": \"8th\", \"ninth\": \"9th\", \n",
    "            \"tenth\": \"10th\", \"eleventh\": \"11th\", \"twelfth\": \"12th\", \n",
    "            \"thirteenth\": \"13th\", \"fourteenth\": \"14th\", \"fifteenth\": \"15th\", \n",
    "            \"sixteenth\": \"16th\", \"seventeenth\": \"17th\", \"eighteenth\": \"18th\", \n",
    "            \"nineteenth\": \"19th\", \"twentieth\": \"20th\",\n",
    "            \"twenty-first\": \"21st\", \"twenty first\": \"21st\",\n",
    "            \"twenty-second\": \"22nd\", \"twenty second\": \"22nd\",\n",
    "            \"twenty-third\": \"23rd\", \"twenty third\": \"23rd\",\n",
    "            \"twenty-fourth\": \"24th\", \"twenty fourth\": \"24th\",\n",
    "            \"twenty-fifth\": \"25th\", \"twenty fifth\": \"25th\",\n",
    "            \"twenty-sixth\": \"26th\", \"twenty sixth\": \"26th\",\n",
    "            \"twenty-seventh\": \"27th\", \"twenty seventh\": \"27th\",\n",
    "            \"twenty-eighth\": \"28th\", \"twenty eighth\": \"28th\",\n",
    "            \"twenty-ninth\": \"29th\", \"twenty ninth\": \"29th\",\n",
    "            \"thirtieth\": \"30th\", \n",
    "            \"thirty-first\": \"31st\", \"thirty first\": \"31st\",\n",
    "            \"last\": \"last\"\n",
    "        }\n",
    "        for word, num in replacements.items():\n",
    "            clean_str = clean_str.replace(word, num)\n",
    "            \n",
    "        parsed = dateparser.parse(clean_str)\n",
    "        return parsed if parsed else pd.NaT\n",
    "\n",
    "    try:\n",
    "        df[col_name] = df[col_name].apply(parse_natural_language)\n",
    "        df[col_name] = df[col_name].dt.strftime(target_format)\n",
    "        print(f\"       [Tool Success] Column updated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"       [Tool Error] Failed: {e}\")\n",
    "    return df\n",
    "\n",
    "def time_agent_workflow(df: pd.DataFrame, col_name: str) -> pd.DataFrame:\n",
    "    print(f\"  -> [Time Agent] Taking control of column: '{col_name}'\")\n",
    "    sample_data = df[col_name].dropna().head(5).tolist()\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Look at this sample of time/date data from the column '{col_name}'.\n",
    "    Data sample: {sample_data}\n",
    "    \n",
    "    Determine the appropriate standardized format for this data based on its granularity.\n",
    "    - Hours and minutes: \"%H:%M\"\n",
    "    - Hours, minutes, and seconds: \"%H:%M:%S\"\n",
    "    - Just seconds: \"%S\"\n",
    "    - Specific dates: \"%d/%m/%Y\"\n",
    "    - Date and time: \"%d/%m/%Y %H:%M\"\n",
    "    - Date and exact time: \"%d/%m/%Y %H:%M:%S\"\n",
    "    - Month and year: \"%m/%Y\"\n",
    "    - Year only: \"%Y\"\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert data formatting agent.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=TimeFormatDecision\n",
    "    )\n",
    "    \n",
    "    decision = response.choices[0].message.parsed\n",
    "    print(f\"     [Time Agent Decision] {decision.reasoning}\")\n",
    "    \n",
    "    df = execute_time_formatting(df, col_name, decision.target_format)\n",
    "    return df\n",
    "\n",
    "\n",
    "def orchestrator_router(file_path: str, type_vector: list[str]):\n",
    "    print(f\"\\n[Orchestrator] Loading '{file_path}' and delegating tasks...\")\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    for col_name, col_type in zip(df.columns, type_vector):\n",
    "        if col_type == \"time\":\n",
    "            df = time_agent_workflow(df, col_name)\n",
    "        elif col_type == \"money\":\n",
    "            df = money_agent_workflow(df, col_name) \n",
    "        elif col_type == \"int\":\n",
    "            df = int_agent_workflow(df, col_name)\n",
    "        elif col_type == \"name\":\n",
    "            df = name_agent_workflow(df, col_name)\n",
    "        elif col_type in [\"string\", \"unknown\"]:\n",
    "            print(f\"  -> [Orchestrator] Bypassing '{col_name}' (Type: {col_type} requires no formatting)\")\n",
    "\n",
    "    \n",
    "    output_path = \"cleaned_\" + file_path\n",
    "    df.to_excel(output_path, index=False)\n",
    "    print(f\"\\n[Orchestrator] All tasks complete. Saved new file to: {output_path}\")\n",
    "\n",
    "\n",
    "class MoneyFormatDecision(BaseModel):\n",
    "    reasoning: str\n",
    "    is_mixed_currency: bool  \n",
    "    detected_currency: str   \n",
    "    scale_decision: Literal[\"None\", \"Thousands\", \"Millions\", \"Billions\"]\n",
    "    decimal_separator: Literal[\".\", \",\"]\n",
    "\n",
    "\n",
    "def execute_money_formatting(df: pd.DataFrame, col_name: str, decision: MoneyFormatDecision) -> pd.DataFrame:\n",
    "    print(f\"       [Tool Executing] Scale: {decision.scale_decision}, Mixed Currency: {decision.is_mixed_currency}...\")\n",
    "    \n",
    "    def parse_money_string(val):\n",
    "        if pd.isna(val):\n",
    "            return pd.NA, \"\"\n",
    "            \n",
    "        val_str = str(val).lower().strip()\n",
    "        original_str = str(val).strip() \n",
    "        \n",
    "        # 1. Extract the currency symbol, code, or full word\n",
    "        # We expanded the regex to look for words like \"dollars\" and \"euros\"\n",
    "        symbol_match = re.search(r'([\\$€£¥]|(?:usd|eur|gbp|jpy|dollars?|euros?|pounds?|yen))', original_str, re.IGNORECASE)\n",
    "        raw_symbol = symbol_match.group(1).lower() if symbol_match else \"\"\n",
    "        \n",
    "        # 2. Normalize the currency so \"dollars\" and \"$\" both become \"USD\"\n",
    "        currency_map = {\n",
    "            \"dollar\": \"USD\", \"dollars\": \"USD\", \"$\": \"USD\", \"usd\": \"USD\",\n",
    "            \"euro\": \"EUR\", \"euros\": \"EUR\", \"eur\": \"EUR\", \"€\": \"EUR\",\n",
    "            \"pound\": \"GBP\", \"pounds\": \"GBP\", \"gbp\": \"GBP\", \"£\": \"GBP\",\n",
    "            \"yen\": \"JPY\", \"jpy\": \"JPY\", \"¥\": \"JPY\"\n",
    "        }\n",
    "        # Get the standard code, or just uppercase it if it's not in the map\n",
    "        symbol = currency_map.get(raw_symbol, raw_symbol.upper())\n",
    "        \n",
    "        # 3. Handle International Decimals\n",
    "        if decision.decimal_separator == \",\":\n",
    "            val_str = val_str.replace('.', '').replace(',', '.')\n",
    "        else:\n",
    "            val_str = val_str.replace(',', '')\n",
    "            \n",
    "        # DEFENSIVE SHIELD: Remove extra dots\n",
    "        if val_str.count('.') > 1:\n",
    "            parts = val_str.rsplit('.', 1)\n",
    "            val_str = parts[0].replace('.', '') + '.' + parts[1]\n",
    "            \n",
    "        # 4. Extract the core number\n",
    "        match = re.search(r'[\\d\\.]+', val_str)\n",
    "        if not match:\n",
    "            return pd.NA, symbol\n",
    "        try:\n",
    "            num = float(match.group())\n",
    "        except ValueError:\n",
    "            return pd.NA, symbol\n",
    "            \n",
    "        # 5. Apply word multipliers\n",
    "        isolated_words = re.sub(r'[\\d\\.\\,€\\$£¥]', ' ', val_str).split()\n",
    "        \n",
    "        if any(w in isolated_words for w in ['billion', 'billions', 'bill', 'bil', 'b']):\n",
    "            num *= 1_000_000_000\n",
    "        elif any(w in isolated_words for w in ['million', 'millions', 'mill', 'mil', 'm']):\n",
    "            num *= 1_000_000\n",
    "        elif any(w in isolated_words for w in ['thousand', 'thousands', 'k']):\n",
    "            num *= 1_000\n",
    "        elif any(w in isolated_words for w in ['cent', 'cents']):\n",
    "            num /= 100\n",
    "            \n",
    "        return num, symbol\n",
    "\n",
    "    try:\n",
    "        # Get a list of (number, symbol) tuples for every row\n",
    "        parsed_data = df[col_name].apply(parse_money_string)\n",
    "        \n",
    "        # Separate the numbers and symbols into two lists\n",
    "        nums = [x[0] if isinstance(x, tuple) else pd.NA for x in parsed_data]\n",
    "        symbols = [x[1] if isinstance(x, tuple) else \"\" for x in parsed_data]\n",
    "        \n",
    "        df[col_name] = nums\n",
    "        \n",
    "        # 5. Apply the Scale Decision\n",
    "        scale_suffix = \"\"\n",
    "        if decision.scale_decision == \"Billions\":\n",
    "            df[col_name] = df[col_name] / 1_000_000_000\n",
    "            scale_suffix = \"in billions\"\n",
    "        elif decision.scale_decision == \"Millions\":\n",
    "            df[col_name] = df[col_name] / 1_000_000\n",
    "            scale_suffix = \"in millions\"\n",
    "        elif decision.scale_decision == \"Thousands\":\n",
    "            df[col_name] = df[col_name] / 1_000\n",
    "            scale_suffix = \"in thousands\"\n",
    "\n",
    "        # 6. Final Formatting: Mixed vs Single Currency\n",
    "        if decision.is_mixed_currency:\n",
    "            # Re-attach the symbol to the number (converts back to string)\n",
    "            def reattach(row_num, row_sym):\n",
    "                if pd.isna(row_num):\n",
    "                    return pd.NA\n",
    "                return f\"{row_sym} {row_num}\".strip()\n",
    "            \n",
    "            df[col_name] = [reattach(n, s) for n, s in zip(df[col_name], symbols)]\n",
    "            \n",
    "            # Rename column if scaling was applied\n",
    "            if scale_suffix:\n",
    "                new_col_name = f\"{col_name} ({scale_suffix})\"\n",
    "                df.rename(columns={col_name: new_col_name}, inplace=True)\n",
    "                print(f\"       [Tool Success] Mixed currencies kept in cells. Renamed to '{new_col_name}'.\")\n",
    "                \n",
    "        else:\n",
    "            # Single currency: Keep as floats, put currency in the header\n",
    "            parts = []\n",
    "            if decision.detected_currency and decision.detected_currency != \"Unknown\":\n",
    "                parts.append(decision.detected_currency)\n",
    "            if scale_suffix:\n",
    "                parts.append(scale_suffix)\n",
    "                \n",
    "            if parts:\n",
    "                header_addition = \" \".join(parts) # e.g., \"USD in millions\"\n",
    "                new_col_name = f\"{col_name} ({header_addition})\"\n",
    "                df.rename(columns={col_name: new_col_name}, inplace=True)\n",
    "                print(f\"       [Tool Success] Floats extracted. Renamed to '{new_col_name}'.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"       [Tool Error] Failed: {e}\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "def money_agent_workflow(df: pd.DataFrame, col_name: str) -> pd.DataFrame:\n",
    "    print(f\"  -> [Money Agent] Taking control of column: '{col_name}'\")\n",
    "    sample_data = df[col_name].dropna().head(10).tolist()\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Look at this sample of financial data from the column '{col_name}'.\n",
    "    Data sample: {sample_data}\n",
    "    \n",
    "    Your task:\n",
    "    1. Identify the primary currency being used (e.g., $, USD, €, Yen, \"dollars\", \"euros\"). \n",
    "       - CRITICAL RULE: If a currency is specified even just once in the sample, and NO OTHER currencies are mentioned, assume that single currency applies to the entire column.\n",
    "    2. Set `is_mixed_currency` to True ONLY if you see multiple DIFFERENT currencies (e.g., \"dollars\" in one row and \"eur\" in another).\n",
    "    3. Determine the best scale (\"None\", \"Thousands\", \"Millions\", \"Billions\").\n",
    "       - Evaluate the TRUE underlying numerical value. \"100 million\" means 100,000,000. \n",
    "       - If the true values are predominantly in the millions, you MUST choose \"Millions\".\n",
    "    4. Identify the decimal separator used in the numbers (\".\" or \",\").\n",
    "       - WARNING: Commas that group thousands (like \"200,000,000\") are NOT decimal separators. If a comma groups thousands, the decimal separator is \".\".\n",
    "       - Only choose \",\" if the comma specifically separates fractional cents at the very end of the number (e.g., \"1.500,00\").\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a precise financial data standardization agent.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=MoneyFormatDecision\n",
    "    )\n",
    "    \n",
    "    decision = response.choices[0].message.parsed\n",
    "    print(f\"     [Money Agent Decision] Mixed: {decision.is_mixed_currency} | Currency: {decision.detected_currency} | Scale: {decision.scale_decision}\")\n",
    "    \n",
    "    df = execute_money_formatting(df, col_name, decision)\n",
    "    return df\n",
    "\n",
    "\n",
    "def execute_int_formatting(df: pd.DataFrame, col_name: str) -> pd.DataFrame:\n",
    "    print(f\"       [Tool Executing] Cleaning and truncating '{col_name}' to integers...\")\n",
    "    \n",
    "    def parse_int(val):\n",
    "        if pd.isna(val):\n",
    "            return pd.NA\n",
    "            \n",
    "        val_str = str(val).lower().replace(',', '').strip()\n",
    "        \n",
    "        try:\n",
    "            num = float(val_str)\n",
    "            return int(num)\n",
    "        except ValueError:\n",
    "            return pd.NA\n",
    "\n",
    "    try:\n",
    "        df[col_name] = df[col_name].apply(parse_int)\n",
    "        df[col_name] = df[col_name].astype('Int64')\n",
    "        \n",
    "        print(f\"       [Tool Success] Column '{col_name}' safely truncated to integers.\")\n",
    "    except Exception as e:\n",
    "        print(f\"       [Tool Error] Failed to process integers: {e}\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "def int_agent_workflow(df: pd.DataFrame, col_name: str) -> pd.DataFrame:\n",
    "    print(f\"  -> [Int Agent] Taking control of column: '{col_name}' (Bypassing LLM for deterministic math)\")\n",
    "    \n",
    "    df = execute_int_formatting(df, col_name)\n",
    "    return df\n",
    "\n",
    "def execute_float_formatting(df: pd.DataFrame, col_name: str) -> pd.DataFrame:\n",
    "    print(f\"       [Tool Executing] Standardizing floats for '{col_name}'...\")\n",
    "    \n",
    "    # 1. Clean the data and convert to pure floats\n",
    "    def extract_float(val):\n",
    "        if pd.isna(val):\n",
    "            return pd.NA\n",
    "        val_str = str(val).lower().replace(',', '').strip()\n",
    "        try:\n",
    "            return float(val_str)\n",
    "        except ValueError:\n",
    "            return pd.NA\n",
    "            \n",
    "    raw_floats = df[col_name].apply(extract_float)\n",
    "    \n",
    "    # 2. Determine the maximum number of decimal places in the column\n",
    "    max_decimals = 0\n",
    "    for val in raw_floats.dropna():\n",
    "        # Convert float to string (e.g., 0.876 -> \"0.876\") and split at the dot\n",
    "        parts = str(val).split('.')\n",
    "        if len(parts) == 2:\n",
    "            decimals = len(parts[1])\n",
    "            if max_decimals < decimals:\n",
    "                max_decimals = decimals\n",
    "                \n",
    "    # 3. Format every number to match the max_decimals length\n",
    "    def pad_float(val):\n",
    "        if pd.isna(val):\n",
    "            return pd.NA\n",
    "        # This dynamically creates a format rule like \"{:.3f}\"\n",
    "        return f\"{val:.{max_decimals}f}\"\n",
    "        \n",
    "    df[col_name] = raw_floats.apply(pad_float)\n",
    "    \n",
    "    print(f\"       [Tool Success] Floats standardized to {max_decimals} decimal places.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def float_agent_workflow(df: pd.DataFrame, col_name: str) -> pd.DataFrame:\n",
    "    print(f\"  -> [Float Agent] Taking control of column: '{col_name}' (Bypassing LLM)\")\n",
    "    \n",
    "    df = execute_float_formatting(df, col_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "class NameFormatDecision(BaseModel):\n",
    "    reasoning: str\n",
    "    entity_type: Literal[\"Human Names\", \"Locations/Other\"]\n",
    "    dominant_format: Literal[\"First Last\", \"Last First\", \"N/A\"]\n",
    "\n",
    "\n",
    "def execute_name_formatting(df: pd.DataFrame, col_name: str, decision: NameFormatDecision) -> pd.DataFrame:\n",
    "    print(f\"       [Tool Executing] Cleaning names. Type: {decision.entity_type}, Format: {decision.dominant_format}...\")\n",
    "    \n",
    "    def parse_name(val):\n",
    "        if pd.isna(val):\n",
    "            return pd.NA\n",
    "            \n",
    "        # 1. Standardize capitalization (e.g., \"JOHN smith\" -> \"John Smith\")\n",
    "        clean_name = str(val).strip().title()\n",
    "        \n",
    "        # 2. If it's a Location/Other, we just return the title-cased string\n",
    "        if decision.entity_type == \"Locations/Other\":\n",
    "            return clean_name\n",
    "            \n",
    "        # 3. Handle Human Names\n",
    "        # If there's a comma (e.g., \"Smith, John\"), split it and force \"First Last\"\n",
    "        if \",\" in clean_name:\n",
    "            parts = [p.strip() for p in clean_name.split(\",\")]\n",
    "            if len(parts) == 2:\n",
    "                return f\"{parts[1]} {parts[0]}\"\n",
    "                \n",
    "        # If the LLM determined the column is mostly \"Last First\" without commas (e.g., \"Smith John\")\n",
    "        if decision.dominant_format == \"Last First\":\n",
    "            parts = clean_name.split()\n",
    "            if len(parts) == 2:\n",
    "                # Flip it to \"First Last\"\n",
    "                return f\"{parts[1]} {parts[0]}\"\n",
    "                \n",
    "        # Default fallback: return as-is (already title-cased)\n",
    "        return clean_name\n",
    "\n",
    "    try:\n",
    "        df[col_name] = df[col_name].apply(parse_name)\n",
    "        print(f\"       [Tool Success] Column '{col_name}' standardized.\")\n",
    "    except Exception as e:\n",
    "        print(f\"       [Tool Error] Failed to process names: {e}\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def name_agent_workflow(df: pd.DataFrame, col_name: str) -> pd.DataFrame:\n",
    "    print(f\"  -> [Name Agent] Taking control of column: '{col_name}'\")\n",
    "    \n",
    "    # Grab 10 rows to give the LLM enough pattern context\n",
    "    sample_data = df[col_name].dropna().head(10).tolist()\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Look at this sample of proper nouns from the column '{col_name}'.\n",
    "    Data sample: {sample_data}\n",
    "    \n",
    "    Your task:\n",
    "    1. Determine if this column primarily contains \"Human Names\" or \"Locations/Other\" (like cities, states, companies).\n",
    "    2. If it is \"Human Names\", deduce the dominant structural format.\n",
    "       - Are they mostly \"First Last\" (e.g., John Smith)?\n",
    "       - Are they mostly \"Last First\" (e.g., Smith John)?\n",
    "       - NOTE: If you see ambiguous names (like \"Harper Taylor\"), look at the other names in the sample to deduce the pattern.\n",
    "    3. If it is \"Locations/Other\", select \"N/A\" for the format.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a precise text standardization agent.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=NameFormatDecision\n",
    "    )\n",
    "    \n",
    "    decision = response.choices[0].message.parsed\n",
    "    print(f\"     [Name Agent Decision] Type: {decision.entity_type} | Dominant Format: {decision.dominant_format}\")\n",
    "    \n",
    "    df = execute_name_formatting(df, col_name, decision)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_file = \"test_pipeline.xlsx\"\n",
    "    pd.DataFrame({\n",
    "        \"Event Date\": [\"first of january 2016\", \"january second 2016\", \"yesterday\"],\n",
    "        \"Revenue\": [\"100 million dollars\", \"200000000\", \"300 mil eur\"],\n",
    "        \"entities\": [5, 10, 15.0],\n",
    "        \"Customer\": [\"Alice\", \"Bob\", \"Charlie SMITH\"]\n",
    "    }).to_excel(test_file, index=False)\n",
    "    \n",
    "    print(\"--- STARTING AGENTIC PIPELINE ---\")\n",
    "\n",
    "    classified_types = reader_agent(test_file)\n",
    "    \n",
    "    orchestrator_router(test_file, classified_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f59d4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first of january 2016', 'january second 2016', 'yesterday']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"first of january 2016\", \"january second 2016\", \"yesterday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f95959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64f5afd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING AGENTIC PIPELINE (MCP + SDK) for cleaned_test_pipeline_mcp.xlsx ---\n",
      "\n",
      "[Orchestrator Summary]:\n",
      "Here's a summary of the actions taken on the columns:\n",
      "\n",
      "- **Event Date**: Formatted as a time column to '%d/%m/%Y' format.\n",
      "- **Revenue**: Formatted as a money column, with mixed currencies handled (assuming USD), and scaled to \"Millions\" with '.' as the decimal separator.\n",
      "- **entities**: Formatted as an integer column.\n",
      "- **Customer**: Standardized as a name column to 'First Last' format.\n",
      "\n",
      "No actions were needed for string or unknown types.\n",
      "\n",
      "[Orchestrator Summary]:\n",
      "Here's a summary of the actions taken on the columns:\n",
      "\n",
      "- **Event Date**: Formatted as a time column to '%d/%m/%Y' format.\n",
      "- **Revenue**: Formatted as a money column, with mixed currencies handled (assuming USD), and scaled to \"Millions\" with '.' as the decimal separator.\n",
      "- **entities**: Formatted as an integer column.\n",
      "- **Customer**: Standardized as a name column to 'First Last' format.\n",
      "\n",
      "No actions were needed for string or unknown types.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "from agents import Agent, Runner, function_tool\n",
    "from agents.mcp import MCPServerStdio\n",
    "import pandas as pd\n",
    "import dateparser\n",
    "import re\n",
    "\n",
    "# 1. Define the MCP Server for Data Formatting Tools\n",
    "# We will write this to a separate file and run it as a subprocess\n",
    "mcp_server_code = r\"\"\"\n",
    "import pandas as pd\n",
    "import dateparser\n",
    "import re\n",
    "from typing import Literal\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"data-formatting-tools\")\n",
    "\n",
    "@mcp.tool()\n",
    "def execute_time_formatting(\n",
    "    file_path: str, \n",
    "    col_name: str, \n",
    "    target_format: Literal[\"%H:%M\", \"%H:%M:%S\", \"%S\", \"%d/%m/%Y\", \"%d/%m/%Y %H:%M\", \"%d/%m/%Y %H:%M:%S\", \"%m/%Y\", \"%Y\"]\n",
    ") -> str:\n",
    "    '''Format a time/date column in an Excel file to a specific target format.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the Excel file.\n",
    "        col_name: Name of the column to format.\n",
    "        target_format: The target strftime format.\n",
    "    '''\n",
    "    print(f\"       [Tool Executing] Formatting '{col_name}' to '{target_format}'...\")\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        def parse_natural_language(date_str):\n",
    "            if pd.isna(date_str):\n",
    "                return pd.NaT\n",
    "                \n",
    "            clean_str = str(date_str).lower()\n",
    "            replacements = {\n",
    "                \"first\": \"1st\", \"second\": \"2nd\", \"third\": \"3rd\", \n",
    "                \"fourth\": \"4th\", \"fifth\": \"5th\", \"sixth\": \"6th\", \n",
    "                \"seventh\": \"7th\", \"eighth\": \"8th\", \"ninth\": \"9th\", \n",
    "                \"tenth\": \"10th\", \"eleventh\": \"11th\", \"twelfth\": \"12th\", \n",
    "                \"thirteenth\": \"13th\", \"fourteenth\": \"14th\", \"fifteenth\": \"15th\", \n",
    "                \"sixteenth\": \"16th\", \"seventeenth\": \"17th\", \"eighteenth\": \"18th\", \n",
    "                \"nineteenth\": \"19th\", \"twentieth\": \"20th\",\n",
    "                \"twenty-first\": \"21st\", \"twenty first\": \"21st\",\n",
    "                \"twenty-second\": \"22nd\", \"twenty second\": \"22nd\",\n",
    "                \"twenty-third\": \"23rd\", \"twenty third\": \"23rd\",\n",
    "                \"twenty-fourth\": \"24th\", \"twenty fourth\": \"24th\",\n",
    "                \"twenty-fifth\": \"25th\", \"twenty fifth\": \"25th\",\n",
    "                \"twenty-sixth\": \"26th\", \"twenty sixth\": \"26th\",\n",
    "                \"twenty-seventh\": \"27th\", \"twenty seventh\": \"27th\",\n",
    "                \"twenty-eighth\": \"28th\", \"twenty eighth\": \"28th\",\n",
    "                \"twenty-ninth\": \"29th\", \"twenty ninth\": \"29th\",\n",
    "                \"thirtieth\": \"30th\", \n",
    "                \"thirty-first\": \"31st\", \"thirty first\": \"31st\",\n",
    "                \"last\": \"last\"\n",
    "            }\n",
    "            for word, num in replacements.items():\n",
    "                clean_str = clean_str.replace(word, num)\n",
    "                \n",
    "            parsed = dateparser.parse(clean_str)\n",
    "            return parsed if parsed else pd.NaT\n",
    "\n",
    "        df[col_name] = df[col_name].apply(parse_natural_language)\n",
    "        df[col_name] = df[col_name].dt.strftime(target_format)\n",
    "        df.to_excel(file_path, index=False)\n",
    "        return f\"Successfully formatted column '{col_name}' to '{target_format}'.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error formatting time: {e}\"\n",
    "\n",
    "@mcp.tool()\n",
    "def execute_money_formatting(\n",
    "    file_path: str, \n",
    "    col_name: str, \n",
    "    is_mixed_currency: bool, \n",
    "    detected_currency: str, \n",
    "    scale_decision: Literal[\"None\", \"Thousands\", \"Millions\", \"Billions\"], \n",
    "    decimal_separator: Literal[\".\", \",\"]\n",
    ") -> str:\n",
    "    '''Format a money/financial column in an Excel file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the Excel file.\n",
    "        col_name: Name of the column to format.\n",
    "        is_mixed_currency: True if multiple currencies are present.\n",
    "        detected_currency: The primary currency detected (e.g., 'USD', 'EUR').\n",
    "        scale_decision: The scale to apply.\n",
    "        decimal_separator: The decimal separator used in the raw data.\n",
    "    '''\n",
    "    print(f\"       [Tool Executing] Scale: {scale_decision}, Mixed Currency: {is_mixed_currency}...\")\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        def parse_money_string(val):\n",
    "            if pd.isna(val):\n",
    "                return pd.NA, \"\"\n",
    "                \n",
    "            val_str = str(val).lower().strip()\n",
    "            original_str = str(val).strip() \n",
    "            \n",
    "            symbol_match = re.search(r'([\\$€£¥]|(?:usd|eur|gbp|jpy|dollars?|euros?|pounds?|yen))', original_str, re.IGNORECASE)\n",
    "            raw_symbol = symbol_match.group(1).lower() if symbol_match else \"\"\n",
    "            \n",
    "            currency_map = {\n",
    "                \"dollar\": \"USD\", \"dollars\": \"USD\", \"$\": \"USD\", \"usd\": \"USD\",\n",
    "                \"euro\": \"EUR\", \"euros\": \"EUR\", \"eur\": \"EUR\", \"€\": \"EUR\",\n",
    "                \"pound\": \"GBP\", \"pounds\": \"GBP\", \"gbp\": \"GBP\", \"£\": \"GBP\",\n",
    "                \"yen\": \"JPY\", \"jpy\": \"JPY\", \"¥\": \"JPY\"\n",
    "            }\n",
    "            symbol = currency_map.get(raw_symbol, raw_symbol.upper())\n",
    "            \n",
    "            if decimal_separator == \",\":\n",
    "                val_str = val_str.replace('.', '').replace(',', '.')\n",
    "            else:\n",
    "                val_str = val_str.replace(',', '')\n",
    "                \n",
    "            if val_str.count('.') > 1:\n",
    "                parts = val_str.rsplit('.', 1)\n",
    "                val_str = parts[0].replace('.', '') + '.' + parts[1]\n",
    "                \n",
    "            match = re.search(r'[\\d\\.]+', val_str)\n",
    "            if not match:\n",
    "                return pd.NA, symbol\n",
    "            try:\n",
    "                num = float(match.group())\n",
    "            except ValueError:\n",
    "                return pd.NA, symbol\n",
    "                \n",
    "            isolated_words = re.sub(r'[\\d\\.\\,€\\$£¥]', ' ', val_str).split()\n",
    "            \n",
    "            if any(w in isolated_words for w in ['billion', 'billions', 'bill', 'bil', 'b']):\n",
    "                num *= 1_000_000_000\n",
    "            elif any(w in isolated_words for w in ['million', 'millions', 'mill', 'mil', 'm']):\n",
    "                num *= 1_000_000\n",
    "            elif any(w in isolated_words for w in ['thousand', 'thousands', 'k']):\n",
    "                num *= 1_000\n",
    "            elif any(w in isolated_words for w in ['cent', 'cents']):\n",
    "                num /= 100\n",
    "                \n",
    "            return num, symbol\n",
    "\n",
    "        parsed_data = df[col_name].apply(parse_money_string)\n",
    "        nums = [x[0] if isinstance(x, tuple) else pd.NA for x in parsed_data]\n",
    "        symbols = [x[1] if isinstance(x, tuple) else \"\" for x in parsed_data]\n",
    "        \n",
    "        df[col_name] = nums\n",
    "        \n",
    "        scale_suffix = \"\"\n",
    "        if scale_decision == \"Billions\":\n",
    "            df[col_name] = df[col_name] / 1_000_000_000\n",
    "            scale_suffix = \"in billions\"\n",
    "        elif scale_decision == \"Millions\":\n",
    "            df[col_name] = df[col_name] / 1_000_000\n",
    "            scale_suffix = \"in millions\"\n",
    "        elif scale_decision == \"Thousands\":\n",
    "            df[col_name] = df[col_name] / 1_000\n",
    "            scale_suffix = \"in thousands\"\n",
    "\n",
    "        if is_mixed_currency:\n",
    "            def reattach(row_num, row_sym):\n",
    "                if pd.isna(row_num):\n",
    "                    return pd.NA\n",
    "                return f\"{row_sym} {row_num}\".strip()\n",
    "            \n",
    "            df[col_name] = [reattach(n, s) for n, s in zip(df[col_name], symbols)]\n",
    "            \n",
    "            if scale_suffix:\n",
    "                new_col_name = f\"{col_name} ({scale_suffix})\"\n",
    "                df.rename(columns={col_name: new_col_name}, inplace=True)\n",
    "                \n",
    "        else:\n",
    "            parts = []\n",
    "            if detected_currency and detected_currency != \"Unknown\":\n",
    "                parts.append(detected_currency)\n",
    "            if scale_suffix:\n",
    "                parts.append(scale_suffix)\n",
    "                \n",
    "            if parts:\n",
    "                header_addition = \" \".join(parts)\n",
    "                new_col_name = f\"{col_name} ({header_addition})\"\n",
    "                df.rename(columns={col_name: new_col_name}, inplace=True)\n",
    "\n",
    "        df.to_excel(file_path, index=False)\n",
    "        return f\"Successfully formatted money column '{col_name}'.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error formatting money: {e}\"\n",
    "\n",
    "@mcp.tool()\n",
    "def execute_int_formatting(file_path: str, col_name: str) -> str:\n",
    "    '''Clean and truncate a column to integers.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the Excel file.\n",
    "        col_name: Name of the column to format.\n",
    "    '''\n",
    "    print(f\"       [Tool Executing] Cleaning and truncating '{col_name}' to integers...\")\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        def parse_int(val):\n",
    "            if pd.isna(val):\n",
    "                return pd.NA\n",
    "            val_str = str(val).lower().replace(',', '').strip()\n",
    "            try:\n",
    "                num = float(val_str)\n",
    "                return int(num)\n",
    "            except ValueError:\n",
    "                return pd.NA\n",
    "\n",
    "        df[col_name] = df[col_name].apply(parse_int)\n",
    "        df[col_name] = df[col_name].astype('Int64')\n",
    "        df.to_excel(file_path, index=False)\n",
    "        return f\"Successfully formatted integer column '{col_name}'.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error formatting integers: {e}\"\n",
    "\n",
    "@mcp.tool()\n",
    "def execute_float_formatting(file_path: str, col_name: str) -> str:\n",
    "    '''Standardize floats for a column.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the Excel file.\n",
    "        col_name: Name of the column to format.\n",
    "    '''\n",
    "    print(f\"       [Tool Executing] Standardizing floats for '{col_name}'...\")\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        def extract_float(val):\n",
    "            if pd.isna(val):\n",
    "                return pd.NA\n",
    "            val_str = str(val).lower().replace(',', '').strip()\n",
    "            try:\n",
    "                return float(val_str)\n",
    "            except ValueError:\n",
    "                return pd.NA\n",
    "                \n",
    "        raw_floats = df[col_name].apply(extract_float)\n",
    "        \n",
    "        max_decimals = 0\n",
    "        for val in raw_floats.dropna():\n",
    "            parts = str(val).split('.')\n",
    "            if len(parts) == 2:\n",
    "                decimals = len(parts[1])\n",
    "                if max_decimals < decimals:\n",
    "                    max_decimals = decimals\n",
    "                    \n",
    "        def pad_float(val):\n",
    "            if pd.isna(val):\n",
    "                return pd.NA\n",
    "            return f\"{val:.{max_decimals}f}\"\n",
    "            \n",
    "        df[col_name] = raw_floats.apply(pad_float)\n",
    "        df.to_excel(file_path, index=False)\n",
    "        return f\"Successfully formatted float column '{col_name}' to {max_decimals} decimal places.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error formatting floats: {e}\"\n",
    "\n",
    "@mcp.tool()\n",
    "def execute_name_formatting(\n",
    "    file_path: str, \n",
    "    col_name: str, \n",
    "    entity_type: Literal[\"Human Names\", \"Locations/Other\"], \n",
    "    dominant_format: Literal[\"First Last\", \"Last First\", \"N/A\"]\n",
    ") -> str:\n",
    "    '''Standardize proper nouns/names in a column.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the Excel file.\n",
    "        col_name: Name of the column to format.\n",
    "        entity_type: 'Human Names' or 'Locations/Other'.\n",
    "        dominant_format: 'First Last', 'Last First', or 'N/A'.\n",
    "    '''\n",
    "    print(f\"       [Tool Executing] Cleaning names. Type: {entity_type}, Format: {dominant_format}...\")\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        def parse_name(val):\n",
    "            if pd.isna(val):\n",
    "                return pd.NA\n",
    "            clean_name = str(val).strip().title()\n",
    "            if entity_type == \"Locations/Other\":\n",
    "                return clean_name\n",
    "            if \",\" in clean_name:\n",
    "                parts = [p.strip() for p in clean_name.split(\",\")]\n",
    "                if len(parts) == 2:\n",
    "                    return f\"{parts[1]} {parts[0]}\"\n",
    "            if dominant_format == \"Last First\":\n",
    "                parts = clean_name.split()\n",
    "                if len(parts) == 2:\n",
    "                    return f\"{parts[1]} {parts[0]}\"\n",
    "            return clean_name\n",
    "\n",
    "        df[col_name] = df[col_name].apply(parse_name)\n",
    "        df.to_excel(file_path, index=False)\n",
    "        return f\"Successfully formatted name column '{col_name}'.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error formatting names: {e}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"stdio\")\n",
    "\"\"\"\n",
    "\n",
    "with open(\"data_formatting_server.py\", \"w\") as f:\n",
    "    f.write(mcp_server_code)\n",
    "\n",
    "# 2. Define local function tools for reading data\n",
    "@function_tool\n",
    "def read_column_sample(file_path: str, col_name: str, n: int = 10) -> str:\n",
    "    \"\"\"Read a sample of data from a specific column in an Excel file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the Excel file.\n",
    "        col_name: Name of the column to sample.\n",
    "        n: Number of rows to sample.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        if col_name not in df.columns:\n",
    "            return f\"Column '{col_name}' not found.\"\n",
    "        sample = df[col_name].dropna().head(n).tolist()\n",
    "        return str(sample)\n",
    "    except Exception as e:\n",
    "        return f\"Error reading sample: {e}\"\n",
    "\n",
    "@function_tool\n",
    "def read_data_sample(file_path: str, n: int = 5) -> str:\n",
    "    \"\"\"Read a sample of the entire dataset from an Excel file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the Excel file.\n",
    "        n: Number of rows to sample.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        sample = df.head(n).to_dict(orient=\"list\")\n",
    "        return str(sample)\n",
    "    except Exception as e:\n",
    "        return f\"Error reading sample: {e}\"\n",
    "\n",
    "@function_tool\n",
    "def get_columns(file_path: str) -> str:\n",
    "    \"\"\"Get the list of columns in an Excel file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the Excel file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        return str(list(df.columns))\n",
    "    except Exception as e:\n",
    "        return f\"Error reading columns: {e}\"\n",
    "\n",
    "# 3. Define the Agents\n",
    "reader_agent = Agent(\n",
    "    name=\"Reader Agent\",\n",
    "    instructions=(\n",
    "        \"You are a precise data analysis agent. Your job is to classify columns in a dataset.\\n\"\n",
    "        \"Use the `read_data_sample` tool to get a sample of the data.\\n\"\n",
    "        \"For each column, determine its data type based on the values.\\n\"\n",
    "        \"You are ONLY allowed to use these exact categories: 'time', 'money', 'int', 'string', 'float', 'name', 'unknown'.\\n\\n\"\n",
    "        \"CRITICAL DEFINITIONS:\\n\"\n",
    "        \"- 'time': Includes standard formats (2023-01-01, 14:30), timestamps, AND natural language dates (e.g., 'first of january 2016', 'Q1 2024', 'yesterday'). If the core meaning represents a date or time, it is 'time', NEVER 'string'.\\n\"\n",
    "        \"- 'money': Includes currency symbols ($100, €50), accounting formats, or financial abbreviations (100 USD) and natural language money expressions ('100 dollars', 'fifty euros'). If the core meaning represents a monetary value, it is 'money', NEVER 'string'.\\n\"\n",
    "        \"- 'int': Whole numbers without decimals.\\n\"\n",
    "        \"- 'float': Numbers containing decimals.\\n\"\n",
    "        \"- 'name': Proper nouns. This includes human names (John Smith, Smith, John), cities, states (Alabama), or company names.\\n\"\n",
    "        \"- 'string': General text, sentences, descriptions, or specific codes (e.g., ID-4552) that have no mathematical or temporal value.\\n\"\n",
    "        \"- 'unknown': Use this ONLY if the column is complete gibberish or you cannot confidently assign it to any other category.\\n\\n\"\n",
    "        \"Return a clear mapping of column names to their classified types.\"\n",
    "    ),\n",
    "    tools=[read_data_sample],\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    ")\n",
    "\n",
    "time_agent = Agent(\n",
    "    name=\"Time Agent\",\n",
    "    instructions=(\n",
    "        \"You are an expert data formatting agent specializing in time and dates.\\n\"\n",
    "        \"When given a file and a column name, first use `read_column_sample` to look at the data.\\n\"\n",
    "        \"Determine the appropriate standardized format for this data based on its granularity:\\n\"\n",
    "        \"- Hours and minutes: '%H:%M'\\n\"\n",
    "        \"- Hours, minutes, and seconds: '%H:%M:%S'\\n\"\n",
    "        \"- Just seconds: '%S'\\n\"\n",
    "        \"- Specific dates: '%d/%m/%Y'\\n\"\n",
    "        \"- Date and time: '%d/%m/%Y %H:%M'\\n\"\n",
    "        \"- Date and exact time: '%d/%m/%Y %H:%M:%S'\\n\"\n",
    "        \"- Month and year: '%m/%Y'\\n\"\n",
    "        \"- Year only: '%Y'\\n\"\n",
    "        \"Finally, use the `execute_time_formatting` tool to apply the format.\"\n",
    "    ),\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    ")\n",
    "\n",
    "money_agent = Agent(\n",
    "    name=\"Money Agent\",\n",
    "    instructions=(\n",
    "        \"You are a precise financial data standardization agent.\\n\"\n",
    "        \"When given a file and a column name, first use `read_column_sample` to look at the data.\\n\"\n",
    "        \"Your task:\\n\"\n",
    "        \"1. Identify the primary currency being used (e.g., $, USD, €, Yen, 'dollars', 'euros').\\n\"\n",
    "        \"   - CRITICAL RULE: If a currency is specified even just once in the sample, and NO OTHER currencies are mentioned, assume that single currency applies to the entire column.\\n\"\n",
    "        \"2. Set `is_mixed_currency` to True ONLY if you see multiple DIFFERENT currencies (e.g., 'dollars' in one row and 'eur' in another).\\n\"\n",
    "        \"3. Determine the best scale ('None', 'Thousands', 'Millions', 'Billions').\\n\"\n",
    "        \"   - Evaluate the TRUE underlying numerical value. '100 million' means 100,000,000.\\n\"\n",
    "        \"   - If the true values are predominantly in the millions, you MUST choose 'Millions'.\\n\"\n",
    "        \"4. Identify the decimal separator used in the numbers ('.' or ',').\\n\"\n",
    "        \"   - WARNING: Commas that group thousands (like '200,000,000') are NOT decimal separators. If a comma groups thousands, the decimal separator is '.'.\\n\"\n",
    "        \"   - Only choose ',' if the comma specifically separates fractional cents at the very end of the number (e.g., '1.500,00').\\n\"\n",
    "        \"Finally, use the `execute_money_formatting` tool to apply the formatting.\"\n",
    "    ),\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    ")\n",
    "\n",
    "name_agent = Agent(\n",
    "    name=\"Name Agent\",\n",
    "    instructions=(\n",
    "        \"You are a precise text standardization agent specializing in proper nouns.\\n\"\n",
    "        \"When given a file and a column name, first use `read_column_sample` to look at the data.\\n\"\n",
    "        \"Your task:\\n\"\n",
    "        \"1. Determine if this column primarily contains 'Human Names' or 'Locations/Other' (like cities, states, companies).\\n\"\n",
    "        \"2. If it is 'Human Names', deduce the dominant structural format.\\n\"\n",
    "        \"   - Are they mostly 'First Last' (e.g., John Smith)?\\n\"\n",
    "        \"   - Are they mostly 'Last First' (e.g., Smith John)?\\n\"\n",
    "        \"   - NOTE: If you see ambiguous names (like 'Harper Taylor'), look at the other names in the sample to deduce the pattern.\\n\"\n",
    "        \"3. If it is 'Locations/Other', select 'N/A' for the format.\\n\"\n",
    "        \"Finally, use the `execute_name_formatting` tool to apply the formatting.\"\n",
    "    ),\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    ")\n",
    "\n",
    "# 4. Define the Orchestrator\n",
    "async def run_agentic_pipeline(file_path: str):\n",
    "    server_path = str(Path(\"data_formatting_server.py\").resolve())\n",
    "    python_executable = sys.executable\n",
    "    \n",
    "    async with MCPServerStdio(\n",
    "        name=\"Data Formatting Tools\",\n",
    "        params={\n",
    "            \"command\": python_executable,\n",
    "            \"args\": [server_path],\n",
    "        },\n",
    "    ) as server:\n",
    "        \n",
    "        orchestrator = Agent(\n",
    "            name=\"Data Pipeline Orchestrator\",\n",
    "            instructions=(\n",
    "                \"You are the orchestrator of a data cleaning pipeline. Follow these steps EXACTLY:\\n\"\n",
    "                \"1. Use the `reader_agent` to classify the columns in the file.\\n\"\n",
    "                \"2. For each column, based on its classified type, take the following action:\\n\"\n",
    "                \"   - 'time': Delegate to `time_agent`.\\n\"\n",
    "                \"   - 'money': Delegate to `money_agent`.\\n\"\n",
    "                \"   - 'name': Delegate to `name_agent`.\\n\"\n",
    "                \"   - 'int': Directly use the `execute_int_formatting` tool (do not use an agent).\\n\"\n",
    "                \"   - 'float': Directly use the `execute_float_formatting` tool (do not use an agent).\\n\"\n",
    "                \"   - 'string' or 'unknown': Bypass and do nothing.\\n\"\n",
    "                \"   CRITICAL: For 'time', 'money', and 'name', you MUST delegate to the respective agents and NOT call the formatting tools directly.\\n\"\n",
    "                \"3. Summarize the actions taken for each column.\"\n",
    "            ),\n",
    "            tools=[\n",
    "                get_columns,\n",
    "                reader_agent.as_tool(tool_name=\"reader_agent\", tool_description=\"Classify the data types of columns in the file.\"),\n",
    "                time_agent.as_tool(tool_name=\"time_agent\", tool_description=\"Format time/date columns. Pass file_path and col_name.\"),\n",
    "                money_agent.as_tool(tool_name=\"money_agent\", tool_description=\"Format money/financial columns. Pass file_path and col_name.\"),\n",
    "                name_agent.as_tool(tool_name=\"name_agent\", tool_description=\"Format name/proper noun columns. Pass file_path and col_name.\")\n",
    "            ],\n",
    "            mcp_servers=[server], # Give orchestrator access to MCP tools (specifically for int and float)\n",
    "            model=\"gpt-4o-2024-08-06\",\n",
    "        )\n",
    "        \n",
    "        # We need to give the sub-agents access to the MCP server and local tools too\n",
    "        time_agent.mcp_servers = [server]\n",
    "        time_agent.tools = [read_column_sample]\n",
    "        \n",
    "        money_agent.mcp_servers = [server]\n",
    "        money_agent.tools = [read_column_sample]\n",
    "        \n",
    "        name_agent.mcp_servers = [server]\n",
    "        name_agent.tools = [read_column_sample]\n",
    "\n",
    "        print(f\"--- STARTING AGENTIC PIPELINE (MCP + SDK) for {file_path} ---\")\n",
    "        result = await Runner.run(\n",
    "            orchestrator,\n",
    "            f\"Please analyze and format the data in '{file_path}'.\"\n",
    "        )\n",
    "        print(\"\\n[Orchestrator Summary]:\")\n",
    "        print(result.final_output)\n",
    "\n",
    "# 5. Run the pipeline\n",
    "test_file_mcp = \"cleaned_test_pipeline_mcp.xlsx\"\n",
    "pd.DataFrame({\n",
    "    \"Event Date\": [\"first of january 2016\", \"january second 2016\", \"yesterday\"],\n",
    "    \"Revenue\": [\"100 million dollars\", \"200000000\", \"300 mil eur\"],\n",
    "    \"entities\": [5, 10, 15.0],\n",
    "    \"Customer\": [\"Alice\", \"Bob\", \"Charlie SMITH\"]\n",
    "}).to_excel(test_file_mcp, index=False)\n",
    "\n",
    "# Run the async function\n",
    "await run_agentic_pipeline(test_file_mcp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackeurope (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
